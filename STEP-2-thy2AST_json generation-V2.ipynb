{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7e44ae-2104-4603-a3b9-8ddcf3044c74",
   "metadata": {},
   "source": [
    "### STEP 2: .THY => .JSON \n",
    "\n",
    "This file contains:\n",
    "- Isabelle definition extraction,\n",
    "- recursive expression parser → AST nodes,\n",
    "- base class CipherExtractor and cipher-family specific classes FeistelExtractor, ARXExtractor, SPNExtractor:\n",
    "  - This makes the code modular and easily extensible. Each extractor implements family-specific logic and produces: AST JSON (nodes + edges + function list) for GNN training\n",
    "  - Feistel specifics: The FeistelExtractor:\n",
    "    - detects F_function, simon_round, get_z_bit_val,\n",
    "    - extracts rotation amounts diversity, swap occurrences,\n",
    "    - computes f_function_complexity and rotation_diversity that feed PDV.\n",
    "  - ARX specifics for Speck: ARXExtractor\n",
    "    - records ADD, ROT, XOR counts and extends to capture exact shift constants\n",
    "  - SPN specifics for PRESENT: SPNExtractor\n",
    "    - counts sbox_layer and player_layer occurrences and extracts function ASTs.\n",
    "    - PDV contains sbox_count and perm_count.\n",
    "\n",
    "- PDV JSON (vector-like features) for MLP training.\n",
    "- pipeline functions to build AST JSON (node/edge) and PDV JSON (vector-like),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688461f9-cc01-4928-b7b9-35f788782106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4592e858-d0af-4311-904b-23874c69e33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31c888b3-42c5-472c-82c6-5e9ecc2defda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CIPHER: Simon \n",
      "\n",
      "\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_64_96 ===\n",
      "Security: 5.51 (medium)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_64_96.thy -> output_ast_V5/Simon/Simon_64_96.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_128_256 ===\n",
      "Security: 10.0 (high)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_128_256.thy -> output_ast_V5/Simon/Simon_128_256.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_48_96 ===\n",
      "Security: 5.08 (medium)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_48_96.thy -> output_ast_V5/Simon/Simon_48_96.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_128_192 ===\n",
      "Security: 10.0 (high)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_128_192.thy -> output_ast_V5/Simon/Simon_128_192.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_32_64 ===\n",
      "Security: 3.89 (low)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_32_64.thy -> output_ast_V5/Simon/Simon_32_64.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_96_96 ===\n",
      "Security: 5.71 (medium)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_96_96.thy -> output_ast_V5/Simon/Simon_96_96.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_48_72 ===\n",
      "Security: 4.0 (low)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_48_72.thy -> output_ast_V5/Simon/Simon_48_72.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_64_128 ===\n",
      "Security: 7.1 (high)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_64_128.thy -> output_ast_V5/Simon/Simon_64_128.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_96_144 ===\n",
      "Security: 7.96 (high)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_96_144.thy -> output_ast_V5/Simon/Simon_96_144.json\n",
      "Simon\n",
      "DEBUG: Parsing F_function with CLEANED RHS: [xor (and (word_rotl 1 x) (word_rotl 8 x)) (word_rotl 2 x)]\n",
      "DEBUG: Parsing simon_round with CLEANED RHS: [(let (x, y) = xy in (xor (xor k (F_function x)) y, x))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size plaintext ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size ciphertext ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(let word_size = block_size div 2; m = key_size div word_size; t = get_num_rounds block_size key_size; z_idx = get_z_array_index block_size key_size in if i ≥ t then current_keys else gen_key_schedule_rec block_size key_size (current_keys @ [if m = 2 then xor (xor (xor (current_keys ! (i - 2)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else if m = 3 then xor (xor (current_keys ! (i - 3)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0)) else if m = 4 then xor (xor (xor (current_keys ! (i - 4)) (F_function (current_keys ! (i - 1)))) (word_of_int (if (get_z_bit_val z_idx (i - m)) then 1 else 0))) (rho_const word_size) else (0::'a word) ] ) (i + 1))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size initial_keys_list]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate st (k#ks) = encrypt_iterate (simon_round k st) ks]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [foldl (λst_new k. decrypt_round_inv k st_new) st (rev ks)]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate xy ks]\n",
      "DEBUG: Parsing decrypt_round_inv with CLEANED RHS: [(let (x_new, y_new) = xy_new in (y_new, xor (xor x_new k) (F_function y_new)))]\n",
      "\n",
      "=== FEISTEL EXTRACTION SUMMARY: Simon_128_128 ===\n",
      "Security: 7.41 (high)\n",
      "Rotation amounts: [8, 1, 2]\n",
      "Z-sequence usage: 0\n",
      "F-function complexity: 5\n",
      "Feistel balance: 0.538\n",
      "Key schedule type: complex\n",
      "Cryptographic functions: ['F_function', 'simon_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'decrypt_round_inv']\n",
      "Total AST nodes: 237\n",
      "Total AST edges: 405\n",
      "Processed Simon_128_128.thy -> output_ast_V5/Simon/Simon_128_128.json\n",
      "Done. Summary saved.\n",
      "\n",
      " CIPHER: Speck \n",
      "\n",
      "\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_128_192 ===\n",
      "Security: 10.0 (high)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_128_192.thy -> output_ast_V5/Speck/Speck_128_192.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_128_256 ===\n",
      "Security: 10.0 (high)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_128_256.thy -> output_ast_V5/Speck/Speck_128_256.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_96_96 ===\n",
      "Security: 5.99 (medium)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_96_96.thy -> output_ast_V5/Speck/Speck_96_96.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_48_72 ===\n",
      "Security: 4.57 (low)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_48_72.thy -> output_ast_V5/Speck/Speck_48_72.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_48_96 ===\n",
      "Security: 5.66 (medium)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_48_96.thy -> output_ast_V5/Speck/Speck_48_96.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_128_128 ===\n",
      "Security: 7.54 (high)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_128_128.thy -> output_ast_V5/Speck/Speck_128_128.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_32_64 ===\n",
      "Security: 4.16 (low)\n",
      "Rotation amounts: [2, 7]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_32_64.thy -> output_ast_V5/Speck/Speck_32_64.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_64_96 ===\n",
      "Security: 5.69 (medium)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_64_96.thy -> output_ast_V5/Speck/Speck_64_96.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_96_144 ===\n",
      "Security: 8.19 (high)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_96_144.thy -> output_ast_V5/Speck/Speck_96_144.json\n",
      "Speck\n",
      "DEBUG: Parsing speck_enc_round with CLEANED RHS: [(let rs_x = word_rotr alpha_shift x; add_sxy = rs_x + y; new_x = xor add_sxy k; ls_y = word_rotl beta_shift y; new_y = xor new_x ls_y in (new_x, new_y))]\n",
      "DEBUG: Parsing speck_dec_round with CLEANED RHS: [(let xor_xy = xor x y; new_y = word_rotr beta_shift xor_xy; xor_xk = xor x k; msub = xor_xk - new_y; new_x = word_rotl alpha_shift msub in (new_x, new_y))]\n",
      "DEBUG: Parsing encrypt with CLEANED RHS: [encrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing decrypt with CLEANED RHS: [decrypt_block block_size key_size x y ks]\n",
      "DEBUG: Parsing gen_key_schedule_rec with CLEANED RHS: [(if i ≥ t then k_keys else (let (new_l, new_k) = speck_enc_round alpha_shift beta_shift (l_keys ! i) (k_keys ! i) (word_of_nat i) in gen_key_schedule_rec alpha_shift beta_shift t (l_keys @ [new_l]) (k_keys @ [new_k]) (i + 1)))]\n",
      "DEBUG: Parsing generate_key_schedule with CLEANED RHS: [generate_key_schedule block_size key_size ks]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [st\" | \"encrypt_iterate alpha_shift beta_shift st (k#ks) = (let (x', y') = speck_enc_round alpha_shift beta_shift (fst st) (snd st) k in encrypt_iterate alpha_shift beta_shift (x', y') ks)]\n",
      "DEBUG: Parsing decrypt_iterate with CLEANED RHS: [st\" | \"decrypt_iterate alpha_shift beta_shift st (k#ks) = (let st' = decrypt_iterate alpha_shift beta_shift st ks in speck_dec_round alpha_shift beta_shift k (fst st') (snd st'))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [encrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "DEBUG: Parsing decrypt_block with CLEANED RHS: [decrypt_iterate (fst (get_shift_params block_size)) (snd (get_shift_params block_size)) (x, y) ks]\n",
      "\n",
      "=== ARX EXTRACTION SUMMARY: Speck_64_128 ===\n",
      "Security: 7.14 (high)\n",
      "Rotation amounts: [8, 3]\n",
      "Shift parameters usage: 1\n",
      "ARX operation balance: 0.867\n",
      "Bidirectional rotations: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt', 'gen_key_schedule_rec', 'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block']\n",
      "Total AST nodes: 189\n",
      "Total AST edges: 320\n",
      "Processed Speck_64_128.thy -> output_ast_V5/Speck/Speck_64_128.json\n",
      "Done. Summary saved.\n",
      "\n",
      " CIPHER: PRESENT \n",
      "\n",
      "\n",
      "PRESENT\n",
      "DEBUG: Parsing present_round with CLEANED RHS: [p_layer_bitwise (sbox_layer (xor ste round_key ))]\n",
      "DEBUG: Parsing present_round_inv with CLEANED RHS: [xor (sbox_layer_inv (p_layer_inv_bitwise ste)) round_key]\n",
      "DEBUG: Parsing sbox_layer with CLEANED RHS: [word_of_int ( ∑i < 16. let shift = 4 * i; nibble_int = (uint s div 2^shift) mod 16 in uint (present_sbox (word_of_int nibble_int)) * 2^shift )]\n",
      "DEBUG: Parsing sbox_layer_inv with CLEANED RHS: [word_of_int ( ∑i < 16. let shift = 4 * i; nibble_int = (uint s div 2^shift) mod 16 in uint (present_sbox_inv (word_of_int nibble_int)) * 2^shift )]\n",
      "DEBUG: Parsing p_layer_bitwise with CLEANED RHS: [word_of_int ( horner_sum of_bool 2 (map (λpos. bit s (inv_into {0..<64} p_layer_map pos)) [0..<64]) )]\n",
      "DEBUG: Parsing p_layer_inv_bitwise with CLEANED RHS: [word_of_int ( horner_sum of_bool 2 (map (λpos. bit s (inv_into {0..<64} p_layer_inv_map pos)) [0..<64]) )]\n",
      "DEBUG: Parsing present_encrypt with CLEANED RHS: [present_encrypt_iterate plaintext (key_schedule key) 32]\n",
      "DEBUG: Parsing present_decrypt with CLEANED RHS: [present_decrypt_iterate ciphertext (rev (key_schedule key)) 32]\n",
      "DEBUG: Parsing present_encrypt_iterate with CLEANED RHS: [state\" | \"present_encrypt_iterate state (k#ks) rounds_left = (if rounds_left = 1 then xor state k else present_encrypt_iterate (present_round state k) ks (rounds_left - 1))]\n",
      "DEBUG: Parsing present_decrypt_iterate with CLEANED RHS: [state\" | \"present_decrypt_iterate state (k#ks) rounds_left = (if rounds_left = 1 then xor state k else present_decrypt_iterate (present_round_inv state k) ks (rounds_left - 1))]\n",
      "DEBUG: Parsing key_schedule with CLEANED RHS: [build_key_list key 32]\n",
      "DEBUG: Parsing key_update with CLEANED RHS: [(let k_rot = word_rotl 61 k; sbox_val_raw = word_slice 76 4 k_rot; sbox_val = present_sbox sbox_val_raw; xor_val_raw = word_slice 15 5 k_rot; xor_val_update = xor xor_val_raw (ucast (word_of_nat r_count :: 5 word)); clear_mask1 = not (push_bit 76 (mask 4)); clear_mask2 = not (push_bit 15 (mask 5)); clear_mask = and clear_mask1 clear_mask2; k_cleared = and k_rot clear_mask; k_sboxed_val = or k_cleared (push_bit 76 (ucast sbox_val :: key80)); k_xored_val = or k_sboxed_val (push_bit 15 (ucast xor_val_update :: key80)) in k_xored_val)]\n",
      "DEBUG: Parsing build_key_list with CLEANED RHS: [[]\" | \"build_key_list key (Suc n) = extract_round_key key # build_key_list (key_update key 1) n]\n",
      "DEBUG: Parsing test_encrypt with CLEANED RHS: [present_encrypt]\n",
      "DEBUG: Parsing test_decrypt with CLEANED RHS: [present_decrypt]\n",
      "\n",
      "=== SPN EXTRACTION SUMMARY: PRESENT_64_80 ===\n",
      "Security: 5.3 (medium)\n",
      "S-box size: 16 (defined: True)\n",
      "Permutation: bit_permutation (size: 64)\n",
      "Confusion-diffusion balance: 0.444\n",
      "Layer separation: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['present_round', 'present_round_inv', 'sbox_layer', 'sbox_layer_inv', 'p_layer_bitwise', 'p_layer_inv_bitwise', 'present_encrypt', 'present_decrypt', 'present_encrypt_iterate', 'present_decrypt_iterate', 'key_schedule', 'key_update', 'build_key_list', 'test_encrypt', 'test_decrypt']\n",
      "Total AST nodes: 289\n",
      "Total AST edges: 475\n",
      "Processed Present_64_80.thy -> output_ast_V5/PRESENT/Present_64_80.json\n",
      "PRESENT\n",
      "DEBUG: Parsing present_round with CLEANED RHS: [p_layer_bitwise (sbox_layer ( xor ste round_key ))]\n",
      "DEBUG: Parsing present_round_inv with CLEANED RHS: [xor (sbox_layer_inv (p_layer_inv_bitwise ste)) round_key]\n",
      "DEBUG: Parsing sbox_layer with CLEANED RHS: [word_of_int ( ∑i < 16. let shift = 4 * i; nibble_int = (uint s div 2^shift) mod 16 in uint (present_sbox (word_of_int nibble_int)) * 2^shift )]\n",
      "DEBUG: Parsing sbox_layer_inv with CLEANED RHS: [word_of_int ( ∑i < 16. let shift = 4 * i; nibble_int = (uint s div 2^shift) mod 16 in uint (present_sbox_inv (word_of_int nibble_int)) * 2^shift )]\n",
      "DEBUG: Parsing p_layer_bitwise with CLEANED RHS: [word_of_int ( horner_sum of_bool 2 (map (λpos. bit s (inv_into {0..<64} p_layer_map pos)) [0..<64]) )]\n",
      "DEBUG: Parsing p_layer_inv_bitwise with CLEANED RHS: [word_of_int ( horner_sum of_bool 2 (map (λpos. bit s (inv_into {0..<64} p_layer_inv_map pos)) [0..<64]) )]\n",
      "DEBUG: Parsing present_encrypt with CLEANED RHS: [present_encrypt_iterate plaintext (key_schedule key) 9]\n",
      "DEBUG: Parsing present_decrypt with CLEANED RHS: [present_decrypt_iterate ciphertext (rev (key_schedule key)) 9]\n",
      "DEBUG: Parsing present_encrypt_iterate with CLEANED RHS: [state\" | \"present_encrypt_iterate state (k#ks) rounds_left = (if rounds_left = 1 then xor state k else present_encrypt_iterate (present_round state k) ks (rounds_left - 1))]\n",
      "DEBUG: Parsing present_decrypt_iterate with CLEANED RHS: [state\" | \"present_decrypt_iterate state (k#ks) rounds_left = (if rounds_left = 1 then xor state k else present_decrypt_iterate (present_round_inv state k) ks (rounds_left - 1))]\n",
      "DEBUG: Parsing key_schedule with CLEANED RHS: [build_key_list key 9]\n",
      "DEBUG: Parsing key_update with CLEANED RHS: [(let k_rot = word_rotl 21 k; sbox_val_raw = word_slice 36 4 k_rot; sbox_val = present_sbox sbox_val_raw; xor_val_raw = word_slice 15 5 k_rot; xor_val_update = xor xor_val_raw (ucast (word_of_nat r_count :: 5 word)); clear_mask1 = not (push_bit 36 (mask 4)); clear_mask2 = not (push_bit 15 (mask 5)); clear_mask = and clear_mask1 clear_mask2; k_cleared = and k_rot clear_mask; k_sboxed_val = or k_cleared (push_bit 36 (ucast sbox_val :: key40)); k_xored_val = or k_sboxed_val (push_bit 15 (ucast xor_val_update :: key40)) in k_xored_val)]\n",
      "DEBUG: Parsing build_key_list with CLEANED RHS: [[]\" | \"build_key_list key (Suc n) = extract_round_key key # build_key_list (key_update key 1) n]\n",
      "DEBUG: Parsing test_encrypt with CLEANED RHS: [present_encrypt]\n",
      "DEBUG: Parsing test_decrypt with CLEANED RHS: [present_decrypt]\n",
      "\n",
      "=== SPN EXTRACTION SUMMARY: PRESENT_64_40 ===\n",
      "Security: 1.46 (low)\n",
      "S-box size: 16 (defined: True)\n",
      "Permutation: bit_permutation (size: 64)\n",
      "Confusion-diffusion balance: 0.444\n",
      "Layer separation: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['present_round', 'present_round_inv', 'sbox_layer', 'sbox_layer_inv', 'p_layer_bitwise', 'p_layer_inv_bitwise', 'present_encrypt', 'present_decrypt', 'present_encrypt_iterate', 'present_decrypt_iterate', 'key_schedule', 'key_update', 'build_key_list', 'test_encrypt', 'test_decrypt']\n",
      "Total AST nodes: 289\n",
      "Total AST edges: 475\n",
      "Processed Present_64_40.thy -> output_ast_V5/PRESENT/Present_64_40.json\n",
      "PRESENT\n",
      "DEBUG: Parsing present_round with CLEANED RHS: [p_layer_bitwise (sbox_layer ( xor ste round_key ))]\n",
      "DEBUG: Parsing present_round_inv with CLEANED RHS: [xor (sbox_layer_inv (p_layer_inv_bitwise ste)) round_key]\n",
      "DEBUG: Parsing sbox_layer with CLEANED RHS: [word_of_int ( ∑i < 16. let shift = 4 * i; nibble_int = (uint s div 2^shift) mod 16 in uint (present_sbox (word_of_int nibble_int)) * 2^shift )]\n",
      "DEBUG: Parsing sbox_layer_inv with CLEANED RHS: [word_of_int ( ∑i < 16. let shift = 4 * i; nibble_int = (uint s div 2^shift) mod 16 in uint (present_sbox_inv (word_of_int nibble_int)) * 2^shift )]\n",
      "DEBUG: Parsing p_layer_bitwise with CLEANED RHS: [word_of_int ( horner_sum of_bool 2 (map (λpos. bit s (inv_into {0..<64} p_layer_map pos)) [0..<64]) )]\n",
      "DEBUG: Parsing p_layer_inv_bitwise with CLEANED RHS: [word_of_int ( horner_sum of_bool 2 (map (λpos. bit s (inv_into {0..<64} p_layer_inv_map pos)) [0..<64]) )]\n",
      "DEBUG: Parsing present_encrypt with CLEANED RHS: [present_encrypt_iterate plaintext (key_schedule key) 32]\n",
      "DEBUG: Parsing present_decrypt with CLEANED RHS: [present_decrypt_iterate ciphertext (rev (key_schedule key)) 32]\n",
      "DEBUG: Parsing present_encrypt_iterate with CLEANED RHS: [state\" | \"present_encrypt_iterate state (k#ks) rounds_left = (if rounds_left = 1 then xor state k else present_encrypt_iterate (present_round state k) ks (rounds_left - 1))]\n",
      "DEBUG: Parsing present_decrypt_iterate with CLEANED RHS: [state\" | \"present_decrypt_iterate state (k#ks) rounds_left = (if rounds_left = 1 then xor state k else present_decrypt_iterate (present_round_inv state k) ks (rounds_left - 1))]\n",
      "DEBUG: Parsing key_schedule with CLEANED RHS: [build_key_list key 32]\n",
      "DEBUG: Parsing key_update with CLEANED RHS: [(let k_rot = word_rotl 61 k; sbox_val1_raw = word_slice 124 4 k_rot; sbox_val1 = present_sbox sbox_val1_raw; sbox_val2_raw = word_slice 120 4 k_rot; sbox_val2 = present_sbox sbox_val2_raw; xor_val_raw = word_slice 62 5 k_rot; xor_val_update = xor xor_val_raw (ucast (word_of_nat r_count :: 5 word)); clear_mask1 = not (push_bit 124 (mask 4)); clear_mask2 = not (push_bit 120 (mask 4)); clear_mask3 = not (push_bit 62 (mask 5)); clear_mask = and clear_mask1 (and clear_mask2 clear_mask3); k_cleared = and k_rot clear_mask; k_sboxed1 = or k_cleared (push_bit 124 (ucast sbox_val1 :: key128)); k_sboxed2 = or k_sboxed1 (push_bit 120 (ucast sbox_val2 :: key128)); k_xored_val = or k_sboxed2 (push_bit 62 (ucast xor_val_update :: key128)) in k_xored_val)]\n",
      "DEBUG: Parsing build_key_list with CLEANED RHS: [[]\" | \"build_key_list key (Suc n) = extract_round_key key # build_key_list (key_update key 1) n]\n",
      "DEBUG: Parsing test_encrypt with CLEANED RHS: [present_encrypt]\n",
      "DEBUG: Parsing test_decrypt with CLEANED RHS: [present_decrypt]\n",
      "\n",
      "=== SPN EXTRACTION SUMMARY: PRESENT_64_128 ===\n",
      "Security: 7.62 (high)\n",
      "S-box size: 16 (defined: True)\n",
      "Permutation: bit_permutation (size: 64)\n",
      "Confusion-diffusion balance: 0.556\n",
      "Layer separation: True\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['present_round', 'present_round_inv', 'sbox_layer', 'sbox_layer_inv', 'p_layer_bitwise', 'p_layer_inv_bitwise', 'present_encrypt', 'present_decrypt', 'present_encrypt_iterate', 'present_decrypt_iterate', 'key_schedule', 'key_update', 'build_key_list', 'test_encrypt', 'test_decrypt']\n",
      "Total AST nodes: 317\n",
      "Total AST edges: 524\n",
      "Processed Present_64_128.thy -> output_ast_V5/PRESENT/Present_64_128.json\n",
      "Done. Summary saved.\n"
     ]
    }
   ],
   "source": [
    "# MORE IN DEPTH EXTRACTION\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import traceback\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "# Import security/attack DB + compute_security_score + label function and profiles\n",
    "from cipher_profiles import SecurityParams, ATTACK_DB, compute_security_score, security_label_from_score, DEFAULT_PARAMS, CIPHER_PROFILES\n",
    "\n",
    "all_label_computations = {}\n",
    "\n",
    "# =============================================================================\n",
    "# ENHANCED UNIFIED PDV PROCESSOR WITH CRYPTOGRAPHIC DEPTH\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "class LineByLineFunctionExtractor:\n",
    "    \"\"\"Extract functions line by line to properly stop at next keywords\"\"\"\n",
    "    @staticmethod \n",
    "    def extract_core_functions(content: str, cipher_family: str, debug: bool = False) -> Tuple[Dict[str, str], List[str]]:\n",
    "        \"\"\"Extract core functions using line-by-line parsing\"\"\"\n",
    "        \n",
    "        clean_content = LineByLineFunctionExtractor._remove_comments(content)\n",
    "        lines = clean_content.split('\\n')\n",
    "        \n",
    "        core_functions = {}  # function_name -> function_body\n",
    "        found_functions = []  # list of function names found\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            line = lines[i].strip()\n",
    "            \n",
    "            # Check if this line starts a function definition\n",
    "            if LineByLineFunctionExtractor._is_function_start(line):\n",
    "                func_name = LineByLineFunctionExtractor._extract_function_name(line)\n",
    "                \n",
    "                # Check if this function matches our core patterns\n",
    "                if func_name and LineByLineFunctionExtractor._is_core_function(func_name, cipher_family):\n",
    "                    # Extract the entire function body\n",
    "                    func_body, new_index = LineByLineFunctionExtractor._extract_function_body(lines, i)\n",
    "                    \n",
    "                    if func_body:\n",
    "                        core_functions[func_name] = func_body\n",
    "                        found_functions.append(func_name)\n",
    "                    \n",
    "                    i = new_index  # Skip to after the function\n",
    "                    continue\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\n=== EXTRACTED CORE FUNCTIONS for {cipher_family} ===\")\n",
    "            for func_name in found_functions:\n",
    "                print(f\"- {func_name}\")\n",
    "                # Print first few lines of the body for verification\n",
    "                body_lines = core_functions[func_name].split('\\n')\n",
    "                preview = '\\n'.join(body_lines[:3]) + \"...\" if len(body_lines) > 3 else core_functions[func_name]\n",
    "                print(f\"  Body preview: {preview[:100]}...\")\n",
    "        \n",
    "        return core_functions, found_functions\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_function_start(line: str) -> bool:\n",
    "        \"\"\"Check if line starts a function definition\"\"\"\n",
    "        return any(line.startswith(keyword) for keyword in \n",
    "                  ['definition', 'fun', 'function', 'primrec'])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extract_function_name(line: str) -> Optional[str]:\n",
    "        \"\"\"Extract function name from definition line\"\"\"\n",
    "        patterns = [\n",
    "            r'^(definition|fun|function|primrec)\\s+(\\w+)\\s*::',\n",
    "            r'^(definition|fun|function|primrec)\\s+(\\w+)\\s*where',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                return match.group(2)\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_core_function(func_name: str, cipher_family: str) -> bool:\n",
    "        \"\"\"FIXED: More accurate core function detection based on actual theory files\"\"\"\n",
    "        \n",
    "        # EXCLUDE configuration and helper functions\n",
    "        excluded_functions = {\n",
    "            'get_num_rounds', 'get_z_array_index', 'get_z_bit_val',\n",
    "            'z0', 'z1', 'z2', 'z3', 'z4', 'rho_const', 'block_size',\n",
    "            'key_size', 'word_size', 'num_rounds', 'get_shift_params',\n",
    "            'alpha', 'beta', 'sbox_table', 'sbox_inv_table', 'p_layer_map',\n",
    "            'p_layer_inv_map', 'extract_round_key', 'word_rotl', 'word_slice',\n",
    "            # --- HIGHT-specific exclusions ---\n",
    "            'get_delta_array_index', 'delta0', 'get_delta_bit_val', 'list_to_byte',\n",
    "            'rotate_bits_left'\n",
    "        }\n",
    "        \n",
    "        if func_name in excluded_functions:\n",
    "            return False\n",
    "        \n",
    "        # Family-specific core functions based on actual theory files\n",
    "        core_functions = {\n",
    "            'Feistel': [  # Simon\n",
    "                'F_function', 'simon_round', 'encrypt', 'decrypt',\n",
    "                'gen_key_schedule_rec', 'generate_key_schedule',\n",
    "                'encrypt_iterate', 'decrypt_iterate', \n",
    "                'encrypt_block', 'decrypt_block', 'decrypt_round_inv'\n",
    "            ],\n",
    "            'ARX': [  # Speck\n",
    "                'speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt',\n",
    "                'gen_key_schedule_rec', 'generate_key_schedule', \n",
    "                'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block'\n",
    "            ],\n",
    "            'SPN': [  # PRESENT\n",
    "                'present_round', 'present_round_inv', 'present_encrypt', 'present_decrypt',\n",
    "                'present_encrypt_iterate', 'present_decrypt_iterate',\n",
    "                'sbox_layer', 'sbox_layer_inv', 'p_layer_bitwise', 'p_layer_inv_bitwise',\n",
    "                'key_update', 'build_key_list', 'key_schedule', 'test_encrypt', 'test_decrypt'\n",
    "            ],\n",
    "            'HIGHT_ARX': [\n",
    "                'F_function_0', 'F_function_1',\n",
    "                'whitening_key_generation',\n",
    "                 #'constant_generation', # 'constant_generation_rec',\n",
    "                 #'subkey_generation', # 'subkey_generation_rec',\n",
    "                'generate_key_schedule_enc', #'generate_key_schedule_dec',\n",
    "                #'encryption_initial_transformation', #'decryption_initial_transformation',\n",
    "                #'encryption_final_transformation', # 'decryption_final_transformation',\n",
    "                'hight_encryption_round', #'hight_decryption_round',\n",
    "                'encrypt_iterate', #'decrypt_iterate',\n",
    "                'encrypt_block', #'decrypt_block',\n",
    "                #'encrypt_64_128', 'decrypt_64_128',\n",
    "                #'generate_key_schedule_enc_64_128', 'generate_key_schedule_dec_64_128'\n",
    "            ]\n",
    "            \n",
    "        }\n",
    "        \n",
    "        if cipher_family in core_functions:\n",
    "            return func_name in core_functions[cipher_family]\n",
    "        \n",
    "        # Fallback: check if function contains cryptographic operations\n",
    "        return any(indicator in func_name.lower() for indicator in \n",
    "                  ['round', 'encrypt', 'decrypt', 'sbox', 'key', 'schedule'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #         expected_functions = {\n",
    "        #     'Feistel': ['F_function', 'simon_round', 'get_num_rounds', 'gen_key_schedule_rec', 'get_num_rounds', 'decrypt_round_inv', 'generate_key_schedule', 'encrypt','decrypt',\n",
    "        #                'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate', 'decrypt_round_inv', \n",
    "        #                'encrypt_block', 'decrypt_block'],\n",
    "        #     'ARX': ['speck_enc_round', 'speck_dec_round', 'gen_key_schedule_rec', 'get_num_rounds', 'encrypt', 'decrypt',\n",
    "        #            'generate_key_schedule', 'encrypt_iterate', 'decrypt_iterate',\n",
    "        #            'encrypt_block', 'decrypt_block'],\n",
    "        #     'SPN': ['present_round', 'gen_key_schedule_rec', 'generate_key_schedule', 'extract_round_key', 'key_schedule', 'present_encrypt', 'present_decrypt',\n",
    "        #            'encrypt_iterate', 'decrypt_iterate', 'encrypt_block', 'decrypt_block', 'build_key_list', \n",
    "        #            'sbox_layer', 'p_layer', 'key_update', 'present_sbox']\n",
    "        # }\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extract_function_body(lines: List[str], start_index: int) -> Tuple[Optional[str], int]:\n",
    "        \"\"\"Extract function body until next definition/fun/function or end\"\"\"\n",
    "        body_lines = []\n",
    "        i = start_index\n",
    "        \n",
    "        # Skip the definition line itself\n",
    "        i += 1\n",
    "        \n",
    "        # Look for the equals sign or where clause to find the actual body start\n",
    "        body_started = False\n",
    "        while i < len(lines):\n",
    "            line = lines[i].strip()\n",
    "            \n",
    "            # Stop if we hit the next function definition\n",
    "            if LineByLineFunctionExtractor._is_function_start(line):\n",
    "                break\n",
    "            \n",
    "            # Stop if we hit lemma/theorem/end OR proof tactics for 'function'\n",
    "            # Stop if we hit any keyword that ends a definition block \n",
    "            stop_keywords = [ 'lemma', 'theorem', 'end', 'by pat_completeness', 'termination', 'apply', 'done', 'subsection', 'section' ]\n",
    "            #stop_keywords = ['lemma', 'theorem', 'end', 'by pat_completeness', 'termination', 'apply', 'done']\n",
    "            if any(line.startswith(keyword) for keyword in stop_keywords):\n",
    "                break\n",
    "            \n",
    "            # Look for the start of the body (after = or where)\n",
    "            if not body_started and ('=' in line or 'where' in line):\n",
    "                body_started = True\n",
    "            \n",
    "            if body_started or line:  # Include the line if body started or if it's non-empty\n",
    "                body_lines.append(line)\n",
    "            i += 1\n",
    "        body = '\\n'.join(body_lines).strip()\n",
    "        return body if body else None, i \n",
    "        \n",
    "    @staticmethod\n",
    "    def _remove_comments(content: str) -> str:\n",
    "        \"\"\"Remove comments completely\"\"\"\n",
    "        no_block_comments = re.sub(r'\\(\\*.*?\\*\\)', '', content, flags=re.DOTALL)\n",
    "        no_comments = re.sub(r'--.*$', '', no_block_comments, flags=re.MULTILINE)\n",
    "        return no_comments\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "class CoreFunctionOperationCounter:\n",
    "    @staticmethod\n",
    "    def count_operations_in_core_functions(content: str, cipher_family: str, debug: bool = False) -> Dict[str, int]:\n",
    "        \"\"\"Count operations in core functions using proper line-by-line extraction\"\"\"\n",
    "        \n",
    "        core_counts = CoreFunctionOperationCounter._empty_counts()\n",
    "        #print('BEF ERRROR')\n",
    "        # Extract core functions using line-by-line approach\n",
    "        core_functions, found_functions = LineByLineFunctionExtractor.extract_core_functions(content, cipher_family, debug)\n",
    "        #print('AFT ERRROR')\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\n=== COUNTING OPERATIONS for {cipher_family} ===\")\n",
    "            print(f\"Found functions: {found_functions}\")\n",
    "        \n",
    "        # Count operations in each core function\n",
    "        for func_name, func_body in core_functions.items():\n",
    "            func_counts = CoreFunctionOperationCounter._count_operations_in_text(func_body, cipher_family)\n",
    "            \n",
    "            if debug and any(func_counts.values()):\n",
    "                non_zero_counts = {k: v for k, v in func_counts.items() if v > 0}\n",
    "                print(f\"{func_name}: {non_zero_counts}\")\n",
    "            \n",
    "            for key in core_counts:\n",
    "                core_counts[key] += func_counts[key]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\n=== FINAL COUNTS for {cipher_family} ===\")\n",
    "            for op, count in core_counts.items():\n",
    "                if count > 0:\n",
    "                    print(f\"{op}: {count}\")\n",
    "        \n",
    "        return core_counts\n",
    "\n",
    "    @staticmethod\n",
    "    def _empty_counts() -> Dict[str, int]: \n",
    "        return { 'xor_count': 0, 'rotl_count': 0, 'rotr_count': 0, 'add_count': 0, 'sub_count': 0, 'and_count': 0, 'sbox_count': 0, 'perm_count': 0, 'z_seq_usage': 0, 'uses_shift_params': 0 }\n",
    "\n",
    "    @staticmethod\n",
    "    def _count_operations_in_text(text: str, cipher_family: str) -> Dict[str, int]:\n",
    "        \"\"\"FIXED: Count operations with family-specific patterns\"\"\"\n",
    "        counts = CoreFunctionOperationCounter._empty_counts()\n",
    "        \n",
    "        # Family-specific operation patterns\n",
    "        if cipher_family == \"Feistel\":  # Simon\n",
    "            patterns = {\n",
    "                'xor_count': r'\\bxor\\b',\n",
    "                'rotl_count': r'\\bword_rotl\\b', \n",
    "                'rotr_count': r'\\bword_rotr\\b',\n",
    "                'and_count': r'\\band\\b',\n",
    "                'z_seq_usage': r'\\b(z0|z1|z2|z3|z4|get_z_bit_val)\\b'\n",
    "            }\n",
    "        elif cipher_family == \"HIGHT_ARX\": # HIGHT \n",
    "            patterns = { 'xor_count': r'\\bxor\\b', 'rotl_count': r'\\b(word_rotl|rotate_bits_left)\\b', # Catches both \n",
    "                         'rotr_count': r'\\b(word_rotr)\\b', # HIGHT doesn't use, but good to have \n",
    "                         'add_count': r'\\+', 'sub_count': r'\\-', 'uses_delta_sequence': r'\\b(delta0|get_delta_bit_val)\\b' # HIGHT specific \n",
    "                       }\n",
    "        elif cipher_family == \"ARX\":  # Speck  \n",
    "            patterns = {\n",
    "                'xor_count': r'\\bxor\\b',\n",
    "                'rotl_count': r'\\bword_rotl\\b',\n",
    "                'rotr_count': r'\\bword_rotr\\b', \n",
    "                'add_count': r'\\+',\n",
    "                'sub_count': r'\\-',\n",
    "                'uses_shift_params': r'\\b(get_shift_params|alpha_shift|beta_shift|alpha|beta)\\b'\n",
    "            }\n",
    "        elif cipher_family == \"SPN\":  # PRESENT\n",
    "            patterns = {\n",
    "                'xor_count': r'\\bxor\\b',\n",
    "                'sbox_count': r'\\b(present_sbox|sbox_layer)\\b',\n",
    "                'perm_count': r'\\b(p_layer_bitwise|p_layer_inv_bitwise|p_layer|p_layer_inv)\\b'\n",
    "            }\n",
    "        else:\n",
    "            patterns = {}\n",
    "        \n",
    "        for op_type, pattern in patterns.items():\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if op_type in counts:\n",
    "                counts[op_type] += len(matches)\n",
    "            else:\n",
    "                counts[op_type] = len(matches) # This handles new keys like 'uses_delta_sequence'\n",
    "        \n",
    "        return counts\n",
    "   \n",
    "\n",
    "class UnifiedPDVProcessor:\n",
    "    def __init__(self):\n",
    "        self.feature_names = [\n",
    "            # Core parameters\n",
    "            'block_size', 'key_size', 'rounds',\n",
    "            # Cipher family indicators\n",
    "            'is_feistel', 'is_arx', 'is_spn', \n",
    "            # Operation counts\n",
    "            'xor_count', 'rotl_count', 'rotr_count', 'add_count', 'sub_count', \n",
    "            'and_count', 'sbox_count', 'perm_count',\n",
    "            # Structural complexity\n",
    "            'round_complexity', 'rotation_diversity', 'max_rotation_amount',\n",
    "            # Core function presence\n",
    "            'has_round_function', 'has_key_schedule', 'has_f_function', \n",
    "            'has_enc_round', 'has_dec_round',\n",
    "            # Graph statistics\n",
    "            'ast_node_count', 'ast_edge_count', 'function_count',\n",
    "            # Cryptographic properties\n",
    "            'uses_z_sequence', 'uses_shift_params', 'uses_sbox', 'uses_permutation',\n",
    "            # Enriched features\n",
    "            'round_function_size', 'operations_per_round',\n",
    "            'complexity_ratio', 'estimated_total_operations',\n",
    "            'key_schedule_operations', 'encryption_operations', 'decryption_operations',\n",
    "            # === ENHANCED CRYPTOGRAPHIC DEPTH FEATURES ===\n",
    "            'crypto_strength_score', 'operation_diversity', \n",
    "            'nonlinearity_density', 'diffusion_strength',\n",
    "            'f_function_richness', 'arx_balance_score',\n",
    "            'sbox_strength', 'confusion_diffusion_ratio',\n",
    "            'layer_separation', 'bidirectional_diffusion',\n",
    "            'cryptographic_pattern_score', 'data_flow_complexity',\n",
    "            'feistel_balance', 'key_schedule_complexity'\n",
    "        ]\n",
    "    \n",
    "    def create_unified_pdv(self, extracted_pdv: Dict, ast_data: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Robust unified PDV creation with comprehensive feature extraction\"\"\"\n",
    "        \n",
    "        try:\n",
    "            cipher_family = extracted_pdv.get(\"cipher_family\", \"\").lower()\n",
    "            is_feistel = 1 if \"feistel\" in cipher_family else 0\n",
    "            is_arx = 1 if \"arx\" in cipher_family else 0\n",
    "            is_spn = 1 if \"spn\" in cipher_family else 0\n",
    "            \n",
    "            # Get operation counts and structure with safe defaults\n",
    "            ops_summary = extracted_pdv.get(\"ops_summary\", {})\n",
    "            \n",
    "            # Extract features from the CORRECT structure based on cipher family\n",
    "            structure = self._get_family_structure(extracted_pdv, cipher_family)\n",
    "            \n",
    "            # Calculate all feature categories\n",
    "            rounds = self._safe_get(extracted_pdv, \"rounds\", 0)\n",
    "            basic_features = self._extract_basic_features(extracted_pdv, cipher_family)\n",
    "            structural_features = self._extract_structural_features(extracted_pdv, cipher_family, structure)\n",
    "            graph_features = self._extract_graph_features(ast_data)\n",
    "            crypto_properties = self._extract_crypto_properties(extracted_pdv, cipher_family, ops_summary)\n",
    "            enriched_features = self._compute_enriched_features(ops_summary, structure, rounds, cipher_family)\n",
    "            crypto_depth_features = self._compute_cryptographic_depth_features(ops_summary, structure, cipher_family, rounds)\n",
    "            ast_crypto_features = self._analyze_ast_cryptographic_patterns(ast_data, cipher_family)\n",
    "            family_specific_features = self._extract_family_specific_features(extracted_pdv, cipher_family)\n",
    "            \n",
    "            # Combine all features\n",
    "            unified = {\n",
    "                **basic_features,\n",
    "                **structural_features,\n",
    "                **graph_features,\n",
    "                **crypto_properties,\n",
    "                **enriched_features,\n",
    "                **crypto_depth_features,\n",
    "                **ast_crypto_features,\n",
    "                **family_specific_features\n",
    "            }\n",
    "            \n",
    "            # Ensure all expected features are present\n",
    "            return self._ensure_feature_completeness(unified)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in unified PDV creation: {e}\")\n",
    "            # Return minimal feature set on error\n",
    "            return self._create_minimal_pdv(extracted_pdv, ast_data)\n",
    "\n",
    "    def _get_family_structure(self, pdv: Dict, cipher_family: str) -> Dict:\n",
    "        \"\"\"Safely extract family-specific structure\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return pdv.get(\"feistel_structure\", {})\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {})\n",
    "        elif \"spn\" in cipher_family:\n",
    "            return pdv.get(\"spn_structure\", {})\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def _safe_get(self, data: Dict, key: str, default: Any = 0) -> Any:\n",
    "        \"\"\"Safely get value from dictionary with error handling\"\"\"\n",
    "        try:\n",
    "            value = data.get(key, default)\n",
    "            return value if value is not None else default\n",
    "        except (KeyError, TypeError):\n",
    "            return default\n",
    "\n",
    "    # def _extract_basic_features(self, pdv: Dict, cipher_family: str) -> Dict[str, Any]:\n",
    "    #     \"\"\"Extract basic cipher parameters\"\"\"\n",
    "    #     return {\n",
    "    #         \"block_size\": self._safe_get(pdv, \"block_size\", 0),\n",
    "    #         \"key_size\": self._safe_get(pdv, \"key_size\", 0),\n",
    "    #         \"rounds\": self._safe_get(pdv, \"rounds\", 0),\n",
    "    #         \"is_feistel\": 1 if \"feistel\" in cipher_family else 0,\n",
    "    #         \"is_arx\": 1 if \"arx\" in cipher_family else 0,\n",
    "    #         \"is_spn\": 1 if \"spn\" in cipher_family else 0,\n",
    "    #     }\n",
    "    # In UnifiedPDVProcessor\n",
    "    def _extract_basic_features(self, pdv: Dict, cipher_family: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract basic cipher parameters AND operation counts\"\"\"\n",
    "        ops_summary = pdv.get(\"ops_summary\", {})\n",
    "        \n",
    "        features = {\n",
    "            \"block_size\": self._safe_get(pdv, \"block_size\", 0),\n",
    "            \"key_size\": self._safe_get(pdv, \"key_size\", 0),\n",
    "            \"rounds\": self._safe_get(pdv, \"rounds\", 0),\n",
    "            \"is_feistel\": 1 if \"feistel\" in cipher_family else 0,\n",
    "            \"is_arx\": 1 if \"arx\" in cipher_family else 0,\n",
    "            \"is_spn\": 1 if \"spn\" in cipher_family else 0,\n",
    "        }\n",
    "        \n",
    "        # === THIS IS THE FIX ===\n",
    "        # Add operation counts - be more defensive\n",
    "        operation_fields = ['xor_count', 'rotl_count', 'rotr_count', 'add_count', \n",
    "                            'sub_count', 'and_count', 'sbox_count', 'perm_count']\n",
    "        for field in operation_fields:\n",
    "            features[field] = ops_summary.get(field, 0)\n",
    "        # =======================\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _extract_structural_features(self, pdv: Dict, cipher_family: str, structure: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Extract structural complexity features\"\"\"\n",
    "        return {\n",
    "            \"round_complexity\": self._extract_round_complexity(pdv, cipher_family),\n",
    "            \"rotation_diversity\": self._extract_rotation_diversity(pdv, cipher_family),\n",
    "            \"max_rotation_amount\": self._extract_max_rotation(pdv, cipher_family),\n",
    "            \"has_round_function\": self._extract_has_round_function(pdv, cipher_family),\n",
    "            \"has_f_function\": self._extract_has_f_function(pdv, cipher_family),\n",
    "            \"has_enc_round\": self._extract_has_enc_round(pdv, cipher_family),\n",
    "            \"has_dec_round\": self._extract_has_dec_round(pdv, cipher_family),\n",
    "            \"has_key_schedule\": self._extract_has_key_schedule(pdv, cipher_family),\n",
    "        }\n",
    "\n",
    "    \n",
    "    def _compute_enriched_features(self, ops_summary: Dict, structure: Dict, rounds: int, cipher_family: str) -> Dict[str, Any]:\n",
    "        \"\"\"Compute enriched features using family-specific knowledge\"\"\"\n",
    "        \n",
    "        # Get round function size based on cipher family\n",
    "        round_function_size = self._get_round_function_size(ops_summary, cipher_family)\n",
    "        \n",
    "        # Operations that would execute per round\n",
    "        operations_per_round = round_function_size\n",
    "        \n",
    "        # Complexity ratio: operations per round relative to total rounds\n",
    "        complexity_ratio = operations_per_round / max(rounds, 1)\n",
    "        \n",
    "        # Estimated total operations (round function × rounds)\n",
    "        estimated_total_operations = operations_per_round * rounds if rounds > 0 else operations_per_round\n",
    "        \n",
    "        # Key schedule operations (family-specific estimates)\n",
    "        key_schedule_ops = self._get_key_schedule_operations(cipher_family, round_function_size)\n",
    "        \n",
    "        # Encryption vs decryption operations\n",
    "        enc_ops, dec_ops = self._get_enc_dec_operations(cipher_family, round_function_size)\n",
    "        \n",
    "        return {\n",
    "            \"round_function_size\": round_function_size,\n",
    "            \"operations_per_round\": operations_per_round,\n",
    "            \"complexity_ratio\": round(complexity_ratio, 4),\n",
    "            \"estimated_total_operations\": estimated_total_operations,\n",
    "            \"key_schedule_operations\": key_schedule_ops,\n",
    "            \"encryption_operations\": enc_ops,\n",
    "            \"decryption_operations\": dec_ops\n",
    "        }\n",
    "\n",
    "    def _compute_cryptographic_depth_features(self, ops_summary: Dict, structure: Dict, cipher_family: str, rounds: int) -> Dict[str, float]:\n",
    "        \"\"\"Compute cryptographic depth metrics for each family\"\"\"\n",
    "        \n",
    "        if \"feistel\" in cipher_family:\n",
    "            return self._feistel_cryptographic_depth(ops_summary, structure, rounds)\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return self._arx_cryptographic_depth(ops_summary, structure, rounds)\n",
    "        elif \"spn\" in cipher_family:\n",
    "            return self._spn_cryptographic_depth(ops_summary, structure, rounds)\n",
    "        else:\n",
    "            return self._generic_cryptographic_depth(ops_summary, structure, rounds)\n",
    "\n",
    "    def _feistel_cryptographic_depth(self, ops_summary: Dict, structure: Dict, rounds: int) -> Dict[str, float]:\n",
    "        \"\"\"Simon-specific cryptographic depth analysis\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # 1. F-function complexity (more nuanced)\n",
    "        f_complexity = structure.get(\"f_function_complexity\", 0)\n",
    "        features['f_function_richness'] = f_complexity / max(rounds, 1)\n",
    "        \n",
    "        # 2. Nonlinearity quality (AND operations provide nonlinearity)\n",
    "        nonlinear_ops = ops_summary.get('and_count', 0)\n",
    "        features['nonlinearity_density'] = nonlinear_ops / max(rounds, 1)\n",
    "        \n",
    "        # 3. Diffusion quality (rotations provide diffusion)\n",
    "        rotation_ops = ops_summary.get('rotl_count', 0) + ops_summary.get('rotr_count', 0)\n",
    "        features['diffusion_strength'] = rotation_ops / max(rounds, 1)\n",
    "        \n",
    "        # 4. Operation diversity (Simon uses XOR, AND, ROTL)\n",
    "        op_diversity = len([op for op in ['xor_count', 'and_count', 'rotl_count'] \n",
    "                           if ops_summary.get(op, 0) > 0])\n",
    "        features['operation_diversity'] = op_diversity\n",
    "        \n",
    "        # 5. Cryptographic strength score\n",
    "        crypto_weights = {\n",
    "            'and_count': 3.0,    # AND provides nonlinearity\n",
    "            'rotl_count': 1.5,   # Rotations provide diffusion\n",
    "            'xor_count': 1.0,    # XOR is linear\n",
    "        }\n",
    "        crypto_strength = sum(ops_summary.get(op, 0) * weight for op, weight in crypto_weights.items())\n",
    "        features['crypto_strength_score'] = crypto_strength / max(rounds, 1)\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _arx_cryptographic_depth(self, ops_summary: Dict, structure: Dict, rounds: int) -> Dict[str, float]:\n",
    "        \"\"\"Speck-specific cryptographic depth analysis\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # 1. ARX operation balance\n",
    "        add_ops = ops_summary.get('add_count', 0)\n",
    "        rot_ops = ops_summary.get('rotl_count', 0) + ops_summary.get('rotr_count', 0)\n",
    "        xor_ops = ops_summary.get('xor_count', 0)\n",
    "        \n",
    "        total_arx_ops = add_ops + rot_ops + xor_ops\n",
    "        features['arx_balance_score'] = min(add_ops, rot_ops, xor_ops) / max(total_arx_ops, 1) if total_arx_ops > 0 else 0\n",
    "        \n",
    "        # 2. Modular addition complexity (stronger than XOR)\n",
    "        features['nonlinearity_density'] = add_ops / max(rounds, 1)\n",
    "        \n",
    "        # 3. Bidirectional diffusion (both left and right rotations)\n",
    "        has_both_rotations = 1.0 if (ops_summary.get('rotl_count', 0) > 0 and \n",
    "                                  ops_summary.get('rotr_count', 0) > 0) else 0.0\n",
    "        features['bidirectional_diffusion'] = has_both_rotations\n",
    "        \n",
    "        # 4. Diffusion strength\n",
    "        features['diffusion_strength'] = rot_ops / max(rounds, 1)\n",
    "        \n",
    "        # 5. Cryptographic strength score\n",
    "        crypto_weights = {\n",
    "            'add_count': 2.5,    # Modular addition is strong\n",
    "            'rotl_count': 1.5,   # Rotations provide diffusion\n",
    "            'rotr_count': 1.5,\n",
    "            'xor_count': 1.0,    # XOR is linear\n",
    "        }\n",
    "        crypto_strength = sum(ops_summary.get(op, 0) * weight for op, weight in crypto_weights.items())\n",
    "        features['crypto_strength_score'] = crypto_strength / max(rounds, 1)\n",
    "        \n",
    "        # 6. Operation diversity\n",
    "        features['operation_diversity'] = len([op for op in ['add_count', 'rotl_count', 'rotr_count', 'xor_count'] \n",
    "                                             if ops_summary.get(op, 0) > 0])\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _spn_cryptographic_depth(self, ops_summary: Dict, structure: Dict, rounds: int) -> Dict[str, float]:\n",
    "        \"\"\"PRESENT-specific cryptographic depth analysis\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # 1. S-box quality metrics\n",
    "        sbox_applications = structure.get(\"sbox_applications\", ops_summary.get('sbox_count', 0))\n",
    "        sbox_size = structure.get(\"sbox_size\", 4)  # 4-bit S-boxes for PRESENT\n",
    "        features['sbox_strength'] = (sbox_applications * math.log2(sbox_size)) / max(rounds, 1)\n",
    "        \n",
    "        # 2. Permutation layer quality\n",
    "        perm_applications = structure.get(\"perm_applications\", ops_summary.get('perm_count', 0))\n",
    "        features['diffusion_strength'] = perm_applications / max(rounds, 1)\n",
    "        \n",
    "        # 3. Confusion-diffusion balance\n",
    "        confusion_ops = ops_summary.get('sbox_count', 0)\n",
    "        diffusion_ops = ops_summary.get('perm_count', 0) + ops_summary.get('xor_count', 0)\n",
    "        features['confusion_diffusion_ratio'] = confusion_ops / max(diffusion_ops, 1) if diffusion_ops > 0 else 0\n",
    "        \n",
    "        # 4. Layer separation (good SPN design)\n",
    "        has_both_layers = 1.0 if (structure.get(\"has_sbox_layer\", 0) and \n",
    "                               structure.get(\"has_perm_layer\", 0)) else 0.0\n",
    "        features['layer_separation'] = has_both_layers\n",
    "        \n",
    "        # 5. Cryptographic strength score\n",
    "        crypto_weights = {\n",
    "            'sbox_count': 5.0,    # S-boxes are cryptographically strongest\n",
    "            'perm_count': 2.0,    # Permutations provide diffusion\n",
    "            'xor_count': 1.0,     # XOR is linear\n",
    "        }\n",
    "        crypto_strength = sum(ops_summary.get(op, 0) * weight for op, weight in crypto_weights.items())\n",
    "        features['crypto_strength_score'] = crypto_strength / max(rounds, 1)\n",
    "        \n",
    "        # 6. Operation diversity\n",
    "        features['operation_diversity'] = len([op for op in ['sbox_count', 'perm_count', 'xor_count'] \n",
    "                                             if ops_summary.get(op, 0) > 0])\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _generic_cryptographic_depth(self, ops_summary: Dict, structure: Dict, rounds: int) -> Dict[str, float]:\n",
    "        \"\"\"Generic cryptographic depth analysis for unknown families\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Basic cryptographic strength calculation\n",
    "        crypto_weights = {\n",
    "            'sbox_count': 5.0, 'and_count': 3.0, 'add_count': 2.5,\n",
    "            'rotl_count': 1.5, 'rotr_count': 1.5, 'perm_count': 2.0,\n",
    "            'xor_count': 1.0, 'sub_count': 2.0\n",
    "        }\n",
    "        \n",
    "        crypto_strength = sum(ops_summary.get(op, 0) * weight for op, weight in crypto_weights.items())\n",
    "        features['crypto_strength_score'] = crypto_strength / max(rounds, 1)\n",
    "        features['operation_diversity'] = len([op for op in crypto_weights.keys() if ops_summary.get(op, 0) > 0])\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _analyze_ast_cryptographic_patterns(self, ast_data: Dict, cipher_family: str) -> Dict[str, float]:\n",
    "        \"\"\"Analyze AST for cryptographic patterns and data flow complexity\"\"\"\n",
    "        nodes = ast_data.get(\"nodes\", [])\n",
    "        edges = ast_data.get(\"edges\", [])\n",
    "        \n",
    "        features = {\n",
    "            'cryptographic_pattern_score': 0.0,\n",
    "            'data_flow_complexity': 0.0\n",
    "        }\n",
    "        \n",
    "        if not nodes:\n",
    "            return features\n",
    "        \n",
    "        # Calculate data flow complexity (edges per node)\n",
    "        features['data_flow_complexity'] = len(edges) / max(len(nodes), 1)\n",
    "        \n",
    "        # Count cryptographic roles in nodes\n",
    "        crypto_roles = {}\n",
    "        for node in nodes:\n",
    "            role = node.get('crypto_role', 'unknown')\n",
    "            crypto_roles[role] = crypto_roles.get(role, 0) + 1\n",
    "        \n",
    "        # Calculate pattern score based on cryptographic role distribution\n",
    "        strong_roles = ['feistel_f_function', 'sbox_substitution', 'modular_addition', 'nonlinear_mixing']\n",
    "        medium_roles = ['diffusion_rotation', 'permutation_layer', 'arx_rotation']\n",
    "        \n",
    "        strong_count = sum(crypto_roles.get(role, 0) for role in strong_roles)\n",
    "        medium_count = sum(crypto_roles.get(role, 0) for role in medium_roles)\n",
    "        \n",
    "        features['cryptographic_pattern_score'] = (\n",
    "            strong_count * 2.0 + medium_count * 1.0\n",
    "        ) / max(len(nodes), 1)\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _get_round_function_size(self, ops_summary: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Get round function size based on cipher family and operation counts\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            # Simon: F_function complexity from structure or estimate\n",
    "            core_ops = ['xor_count', 'rotl_count', 'and_count']\n",
    "            return min(8, max(6, sum(ops_summary.get(op, 0) for op in core_ops)))\n",
    "        elif \"arx\" in cipher_family:\n",
    "            # Speck: 1 ROTR + 1 ADD + 2 XOR + 1 ROTL ≈ 5-6\n",
    "            core_ops = ['xor_count', 'rotl_count', 'rotr_count', 'add_count']\n",
    "            return min(6, max(5, sum(ops_summary.get(op, 0) for op in core_ops)))\n",
    "        elif \"spn\" in cipher_family:\n",
    "            # PRESENT: S-box + permutation + key mixing ≈ 2-3\n",
    "            core_ops = ['sbox_count', 'perm_count', 'xor_count']\n",
    "            return min(3, max(2, sum(ops_summary.get(op, 0) for op in core_ops)))\n",
    "        else:\n",
    "            return sum(ops_summary.values()) // 2\n",
    "\n",
    "    def _get_key_schedule_operations(self, cipher_family: str, round_function_size: int) -> int:\n",
    "        \"\"\"Get key schedule operations based on cipher family\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return max(1, round_function_size // 2)\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return max(1, round_function_size // 2)\n",
    "        elif \"spn\" in cipher_family:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _get_enc_dec_operations(self, cipher_family: str, round_function_size: int) -> Tuple[int, int]:\n",
    "        \"\"\"Get encryption vs decryption operations based on cipher family\"\"\"\n",
    "        return round_function_size, round_function_size\n",
    "        \n",
    "\n",
    "    def _extract_round_complexity(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract round complexity from the correct family-specific structure\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return pdv.get(\"feistel_structure\", {}).get(\"f_function_complexity\", 0)\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {}).get(\"enc_round_complexity\", 0)\n",
    "        elif \"spn\" in cipher_family:\n",
    "            return pdv.get(\"spn_structure\", {}).get(\"round_complexity\", 0)\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    def _extract_round_complexity(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract round complexity from the correct family-specific structure\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return pdv.get(\"feistel_structure\", {}).get(\"f_function_complexity\", 0)\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {}).get(\"enc_round_complexity\", 0)\n",
    "        elif \"spn\" in cipher_family:\n",
    "            return pdv.get(\"spn_structure\", {}).get(\"round_complexity\", 0)\n",
    "        return 0\n",
    "    \n",
    "    def _extract_rotation_diversity(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract rotation diversity from the correct family-specific structure\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return pdv.get(\"feistel_structure\", {}).get(\"rotation_diversity\", 0)\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {}).get(\"rotation_diversity\", 0)\n",
    "        return 0\n",
    " \n",
    "    def _extract_max_rotation(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract maximum rotation amount from the correct family-specific structure\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return pdv.get(\"feistel_structure\", {}).get(\"max_rotation_amount\", 0)\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {}).get(\"max_rotation_amount\", 0)\n",
    "        return 0\n",
    "    \n",
    "    def _extract_has_round_function(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract has_round_function from the correct family-specific structure\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return pdv.get(\"feistel_structure\", {}).get(\"has_round_function\", 0)\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {}).get(\"has_enc_round\", 0)\n",
    "        elif \"spn\" in cipher_family:\n",
    "            return pdv.get(\"spn_structure\", {}).get(\"has_round_function\", 0)\n",
    "        return 0\n",
    "    \n",
    "    def _extract_has_f_function(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract has_f_function - primarily for Feistel ciphers\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return pdv.get(\"feistel_structure\", {}).get(\"has_f_function\", 0)\n",
    "        return 0\n",
    "    \n",
    "    def _extract_has_enc_round(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract has_enc_round - primarily for ARX ciphers\"\"\"\n",
    "        if \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {}).get(\"has_enc_round\", 0)\n",
    "        if \"feistel\" in cipher_family or \"spn\" in cipher_family:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def _extract_has_dec_round(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract has_dec_round - primarily for ARX ciphers\"\"\"\n",
    "        if \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {}).get(\"has_dec_round\", 0)\n",
    "        if \"feistel\" in cipher_family or \"spn\" in cipher_family:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def _extract_has_key_schedule(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract has_key_schedule from the correct family-specific structure\"\"\"\n",
    "        if \"feistel\" in cipher_family:\n",
    "            return pdv.get(\"feistel_structure\", {}).get(\"has_key_schedule\", 0)\n",
    "        elif \"arx\" in cipher_family:\n",
    "            return pdv.get(\"arx_structure\", {}).get(\"has_key_schedule\", 0)\n",
    "        elif \"spn\" in cipher_family:\n",
    "            return pdv.get(\"spn_structure\", {}).get(\"has_key_schedule\", 0)\n",
    "        return 0\n",
    "    \n",
    "    def _extract_uses_shift_params(self, pdv: Dict, cipher_family: str) -> int:\n",
    "        \"\"\"Extract uses_shift_params - primarily for ARX ciphers like Speck\"\"\"\n",
    "        if \"arx\" in cipher_family:\n",
    "            return 1 if pdv.get(\"shift_parameters\", {}).get(\"shift_params_defined\", False) else 0\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    def _extract_graph_features(self, ast_data: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Extract graph statistics from AST\"\"\"\n",
    "        return {\n",
    "            \"ast_node_count\": len(ast_data.get(\"nodes\", [])),\n",
    "            \"ast_edge_count\": len(ast_data.get(\"edges\", [])),\n",
    "            \"function_count\": len(ast_data.get(\"functions\", [])),\n",
    "        }\n",
    "\n",
    "    def _extract_crypto_properties(self, pdv: Dict, cipher_family: str, ops_summary: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Extract cryptographic properties\"\"\"\n",
    "        return {\n",
    "            \"uses_z_sequence\": self._safe_get(ops_summary, \"z_seq_usage\", 0),\n",
    "            \"uses_shift_params\": self._extract_uses_shift_params(pdv, cipher_family),\n",
    "            \"uses_sbox\": 1 if self._safe_get(ops_summary, \"sbox_count\", 0) > 0 else 0,\n",
    "            \"uses_permutation\": 1 if self._safe_get(ops_summary, \"perm_count\", 0) > 0 else 0,\n",
    "        }\n",
    "\n",
    "    def _extract_family_specific_features(self, pdv: Dict, cipher_family: str) -> Dict[str, Any]:\n",
    "        \"\"\"Extract family-specific features\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        if \"feistel\" in cipher_family:\n",
    "            structure = pdv.get(\"feistel_structure\", {})\n",
    "            features.update({\n",
    "                \"feistel_balance\": self._safe_get(structure, \"feistel_balance\", 0.0),\n",
    "                \"key_schedule_complexity\": self._map_key_schedule_complexity(\n",
    "                    self._safe_get(structure, \"key_schedule_complexity\", \"simple\")\n",
    "                )\n",
    "            })\n",
    "        elif \"arx\" in cipher_family:\n",
    "            structure = pdv.get(\"arx_structure\", {})\n",
    "            features.update({\n",
    "                \"arx_balance_score\": self._safe_get(structure, \"arx_operation_balance\", 0.0)\n",
    "            })\n",
    "        elif \"spn\" in cipher_family:\n",
    "            structure = pdv.get(\"spn_structure\", {})\n",
    "            features.update({\n",
    "                \"confusion_diffusion_ratio\": self._safe_get(structure, \"confusion_diffusion_balance\", 0.0)\n",
    "            })\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _map_key_schedule_complexity(self, complexity: str) -> float:\n",
    "        \"\"\"Map key schedule complexity to numeric value\"\"\"\n",
    "        complexity_map = {\n",
    "            \"simple\": 1.0,\n",
    "            \"moderate\": 2.0,\n",
    "            \"complex\": 3.0\n",
    "        }\n",
    "        return complexity_map.get(complexity.lower(), 1.0)\n",
    "\n",
    "    def _ensure_feature_completeness(self, unified: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Ensure all expected features are present with default values\"\"\"\n",
    "        for feature in self.feature_names:\n",
    "            if feature not in unified:\n",
    "                unified[feature] = 0.0  # Default value for missing features\n",
    "        return unified\n",
    "\n",
    "    def _create_minimal_pdv(self, extracted_pdv: Dict, ast_data: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Create minimal PDV when full extraction fails\"\"\"\n",
    "        return {\n",
    "            \"block_size\": extracted_pdv.get(\"block_size\", 0),\n",
    "            \"key_size\": extracted_pdv.get(\"key_size\", 0),\n",
    "            \"rounds\": extracted_pdv.get(\"rounds\", 0),\n",
    "            \"is_feistel\": 0,\n",
    "            \"is_arx\": 0,\n",
    "            \"is_spn\": 0,\n",
    "            # Set all other features to 0\n",
    "            **{feature: 0.0 for feature in self.feature_names if feature not in [\n",
    "                \"block_size\", \"key_size\", \"rounds\", \"is_feistel\", \"is_arx\", \"is_spn\"\n",
    "            ]}\n",
    "        }\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# FIXED ExpressionParser: Robust parsing for ALL cipher families\n",
    "# ----------------------------\n",
    "class ExpressionParser:\n",
    "    @staticmethod\n",
    "    def parse_expr_improved(expr: str) -> Dict[str, Any]:\n",
    "        \"\"\"REWRITTEN: Robust parser for complex Isabelle expressions\"\"\"\n",
    "        e = expr.strip()\n",
    "        \n",
    "        # Remove trailing semicolons\n",
    "        if e.endswith(';'):\n",
    "            e = e[:-1].strip()\n",
    "\n",
    "        # Handle surrounding parentheses (balanced)\n",
    "        while e.startswith('(') and e.endswith(')'):\n",
    "            depth = 0\n",
    "            valid = True\n",
    "            for i, ch in enumerate(e):\n",
    "                if ch == '(': depth += 1\n",
    "                elif ch == ')': depth -= 1\n",
    "                if depth == 0 and i < len(e) - 1:\n",
    "                    valid = False\n",
    "                    break\n",
    "            if not valid: break\n",
    "            e = e[1:-1].strip()\n",
    "\n",
    "        # LET expressions\n",
    "        if e.startswith('let'):\n",
    "            let_match = re.match(r'let\\s+(.*?)\\s+in\\s+(.*)$', e, re.DOTALL)\n",
    "            if let_match:\n",
    "                bindings_raw, body_raw = let_match.group(1).strip(), let_match.group(2).strip()\n",
    "                bindings = ExpressionParser.parse_bindings(bindings_raw)\n",
    "                body = ExpressionParser.parse_expr_improved(body_raw)\n",
    "                return {\"op\": \"LET\", \"bindings\": bindings, \"body\": body}\n",
    "\n",
    "        # IF expressions\n",
    "        if e.startswith('if '):\n",
    "            depth = 0\n",
    "            then_pos = else_pos = -1\n",
    "            for i, char in enumerate(e):\n",
    "                if char in '([{': depth += 1\n",
    "                elif char in ')]}': depth -= 1\n",
    "                elif depth == 0:\n",
    "                    if then_pos == -1 and e[i:i+4] == 'then':\n",
    "                        then_pos = i\n",
    "                    elif else_pos == -1 and e[i:i+4] == 'else':\n",
    "                        else_pos = i\n",
    "            if then_pos != -1 and else_pos != -1:\n",
    "                condition = e[2:then_pos].strip()\n",
    "                then_branch = e[then_pos+4:else_pos].strip()\n",
    "                else_branch = e[else_pos+4:].strip()\n",
    "                return {\n",
    "                    \"op\": \"IF\", \n",
    "                    \"condition\": ExpressionParser.parse_expr_improved(condition),\n",
    "                    \"then\": ExpressionParser.parse_expr_improved(then_branch),\n",
    "                    \"else\": ExpressionParser.parse_expr_improved(else_branch)\n",
    "                }\n",
    "\n",
    "        # CRITICAL FIX: Handle rotation operations FIRST before general function application\n",
    "        rotation_match = ExpressionParser._match_rotation_operation(e)\n",
    "        if rotation_match:\n",
    "            return rotation_match\n",
    "\n",
    "        # Handle mathematical operations\n",
    "        operators = [\n",
    "            (r'=', 'EQ'), (r'<', 'LT'), (r'>', 'GT'),\n",
    "            (r'\\+', 'ADD'), (r'-', 'SUB'), \n",
    "            (r'\\*', 'MUL'), (r'\\bdiv\\b', 'DIV'), (r'\\bmod\\b', 'MOD'),\n",
    "            (r'∧', 'AND')\n",
    "        ]\n",
    "        \n",
    "        for op_pattern, op_name in operators:\n",
    "            depth = 0\n",
    "            for i in range(len(e)-1, -1, -1):\n",
    "                if e[i] in ')]}': depth += 1\n",
    "                elif e[i] in '([{': depth -= 1\n",
    "                elif depth == 0:\n",
    "                    substr = e[i:]\n",
    "                    match = re.match(op_pattern, substr)\n",
    "                    if match:\n",
    "                        op_len = len(match.group(0))\n",
    "                        left = e[:i].strip()\n",
    "                        right = e[i+op_len:].strip()\n",
    "                        if left and right:\n",
    "                            return {\n",
    "                                \"op\": op_name,\n",
    "                                \"left\": ExpressionParser.parse_expr_improved(left),\n",
    "                                \"right\": ExpressionParser.parse_expr_improved(right)\n",
    "                            }\n",
    "\n",
    "        # Handle function applications (space-separated Isabelle style)\n",
    "        # Use improved tokenization that respects parentheses\n",
    "        tokens = ExpressionParser.tokenize_respecting_parentheses(e)\n",
    "        if len(tokens) > 1:\n",
    "            func = tokens[0]\n",
    "            args = tokens[1:]\n",
    "            parsed_args = [ExpressionParser.parse_expr_improved(arg) for arg in args]\n",
    "            \n",
    "            func_lower = func.lower()\n",
    "            \n",
    "            # Bitwise operations\n",
    "            if func_lower in ('xor', 'and', 'or'):\n",
    "                return {\"op\": func_lower.upper(), \"args\": parsed_args}\n",
    "            \n",
    "            # Tuple operations\n",
    "            elif func_lower in ('fst', 'snd'):\n",
    "                if parsed_args:\n",
    "                    return {\"op\": func_lower.upper(), \"arg\": parsed_args[0]}\n",
    "            \n",
    "            # List operations\n",
    "            elif func_lower in ('take', 'drop', 'tl', 'hd', 'rev'):\n",
    "                return {\"op\": \"LIST_\" + func_lower.upper(), \"args\": parsed_args}\n",
    "            \n",
    "            # Special functions\n",
    "            elif func_lower == 'f':\n",
    "                return {\"op\": \"F_FUNCTION\", \"args\": parsed_args}\n",
    "            \n",
    "            # Generic function application\n",
    "            return {\"op\": \"APPLY\", \"func\": func, \"args\": parsed_args}\n",
    "\n",
    "        # Handle list operations\n",
    "        if '!' in e and '!=' not in e:\n",
    "            parts = e.split('!', 1)\n",
    "            if len(parts) == 2:\n",
    "                return {\n",
    "                    \"op\": \"LIST_INDEX\",\n",
    "                    \"list\": ExpressionParser.parse_expr_improved(parts[0].strip()),\n",
    "                    \"index\": ExpressionParser.parse_expr_improved(parts[1].strip())\n",
    "                }\n",
    "        \n",
    "        if '@' in e:\n",
    "            parts = e.split('@', 1)\n",
    "            if len(parts) == 2:\n",
    "                return {\n",
    "                    \"op\": \"LIST_CONCAT\",\n",
    "                    \"left\": ExpressionParser.parse_expr_improved(parts[0].strip()),\n",
    "                    \"right\": ExpressionParser.parse_expr_improved(parts[1].strip())\n",
    "                }\n",
    "\n",
    "        # Handle literals\n",
    "        if e.isdigit():\n",
    "            return {\"literal\": int(e)}\n",
    "        elif e.startswith('0x'):\n",
    "            try:\n",
    "                return {\"literal\": int(e, 16)}\n",
    "            except ValueError:\n",
    "                pass\n",
    "        elif e.startswith('0b'):\n",
    "            try:\n",
    "                return {\"literal\": int(e[2:], 2)}\n",
    "            except ValueError:\n",
    "                pass\n",
    "        elif e.startswith('\"') and e.endswith('\"'):\n",
    "            return {\"string\": e[1:-1]}\n",
    "\n",
    "        # Fallback: variable or unparsed expression\n",
    "        return {\"var\": e}\n",
    "\n",
    "    @staticmethod\n",
    "    def _match_rotation_operation(expr: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"CRITICAL FIX: Detect rotation operations in complex expressions\"\"\"\n",
    "        # Pattern 1: Simple rotations - word_rotl amount arg\n",
    "        simple_rot_match = re.match(\n",
    "            r'^\\s*(word_rotl|word_rotr|rotl|rotr)\\s+(\\S+)\\s+(.+)$', \n",
    "            expr, re.IGNORECASE\n",
    "        )\n",
    "        if simple_rot_match:\n",
    "            func = simple_rot_match.group(1).lower()\n",
    "            amount = simple_rot_match.group(2).strip()\n",
    "            arg = simple_rot_match.group(3).strip()\n",
    "            \n",
    "            op_type = \"ROTL\" if \"rotl\" in func else \"ROTR\"\n",
    "            return {\n",
    "                \"op\": op_type,\n",
    "                \"amount\": ExpressionParser.parse_expr_improved(amount),\n",
    "                \"arg\": ExpressionParser.parse_expr_improved(arg)\n",
    "            }\n",
    "        \n",
    "        # Pattern 2: Rotations with parenthesized arguments - word_rotl amount (complex expr)\n",
    "        paren_rot_match = re.match(\n",
    "            r'^\\s*(word_rotl|word_rotr|rotl|rotr)\\s+(\\S+)\\s*\\((.*)\\)\\s*$', \n",
    "            expr, re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "        if paren_rot_match:\n",
    "            func = paren_rot_match.group(1).lower()\n",
    "            amount = paren_rot_match.group(2).strip()\n",
    "            arg = f\"({paren_rot_match.group(3).strip()})\"  # Keep parentheses for parsing\n",
    "            \n",
    "            op_type = \"ROTL\" if \"rotl\" in func else \"ROTR\"\n",
    "            return {\n",
    "                \"op\": op_type,\n",
    "                \"amount\": ExpressionParser.parse_expr_improved(amount),\n",
    "                \"arg\": ExpressionParser.parse_expr_improved(arg)\n",
    "            }\n",
    "        \n",
    "        # Pattern 3: Deep search for rotation keywords anywhere in expression\n",
    "        if re.search(r'\\b(word_rotl|word_rotr|rotl|rotr)\\b', expr, re.IGNORECASE):\n",
    "            # Try to extract rotation operation from complex expression\n",
    "            tokens = expr.split()\n",
    "            for i, token in enumerate(tokens):\n",
    "                token_lower = token.lower()\n",
    "                if token_lower in ('word_rotl', 'word_rotr', 'rotl', 'rotr') and i + 1 < len(tokens):\n",
    "                    # Found rotation keyword, try to parse amount and argument\n",
    "                    amount = tokens[i + 1]\n",
    "                    # The argument is everything after the amount\n",
    "                    arg_tokens = tokens[i + 2:]\n",
    "                    if arg_tokens:\n",
    "                        arg = ' '.join(arg_tokens)\n",
    "                        op_type = \"ROTL\" if \"rotl\" in token_lower else \"ROTR\"\n",
    "                        return {\n",
    "                            \"op\": op_type,\n",
    "                            \"amount\": ExpressionParser.parse_expr_improved(amount),\n",
    "                            \"arg\": ExpressionParser.parse_expr_improved(arg)\n",
    "                        }\n",
    "        \n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize_respecting_parentheses(expr: str) -> List[str]:\n",
    "        \"\"\"IMPROVED: Tokenize while keeping parenthesized expressions together\"\"\"\n",
    "        tokens = []\n",
    "        current = []\n",
    "        depth = 0\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(expr):\n",
    "            char = expr[i]\n",
    "            \n",
    "            if char == '(':\n",
    "                if depth == 0 and current:\n",
    "                    # Save current token before starting parentheses\n",
    "                    token = ''.join(current).strip()\n",
    "                    if token:\n",
    "                        tokens.append(token)\n",
    "                    current = []\n",
    "                depth += 1\n",
    "                current.append(char)\n",
    "            elif char == ')':\n",
    "                depth -= 1\n",
    "                current.append(char)\n",
    "                if depth == 0:\n",
    "                    # Finished parenthesized expression\n",
    "                    token = ''.join(current).strip()\n",
    "                    if token:\n",
    "                        tokens.append(token)\n",
    "                    current = []\n",
    "            elif char == ' ' and depth == 0:\n",
    "                if current:\n",
    "                    token = ''.join(current).strip()\n",
    "                    if token:\n",
    "                        tokens.append(token)\n",
    "                    current = []\n",
    "            else:\n",
    "                current.append(char)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        # Don't forget the last token\n",
    "        if current:\n",
    "            token = ''.join(current).strip()\n",
    "            if token:\n",
    "                tokens.append(token)\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_bindings(bindings_str: str) -> Dict[str, Any]:\n",
    "        \"\"\"Parse let-bindings with pattern matching.\"\"\"\n",
    "        bindings = {}\n",
    "        parts = [p.strip() for p in re.split(r'[;\\n]', bindings_str) if p.strip()]\n",
    "        for part in parts:\n",
    "            if '=' in part:\n",
    "                left, right = part.split('=', 1)\n",
    "                bindings[left.strip()] = ExpressionParser.parse_expr_improved(right.strip())\n",
    "        return bindings\n",
    "\n",
    "    \n",
    "# ----------------------------\n",
    "# FIXED: Enhanced extractor classes with consistent operation counting\n",
    "# ----------------------------\n",
    "class CipherExtractor(ABC):\n",
    "    \n",
    "    def __init__(self, thy_path: str, profile: Dict[str, Any]):\n",
    "        self.thy_path = thy_path\n",
    "        self.profile = profile\n",
    "        self.content = self._read_file(thy_path)\n",
    "        family = CIPHER_PROFILES.get(self.profile, {}).get(\"family\", \"\")\n",
    "        all_funcs, _ = LineByLineFunctionExtractor.extract_core_functions(self.content, family, debug=False)\n",
    "\n",
    "        self.definitions = list(all_funcs.items())\n",
    "\n",
    "        self.nodes: List[Dict] = []\n",
    "        self.edges: List[Dict] = []\n",
    "        self.functions: List[str] = []\n",
    "        self.pdv: Dict[str, Any] = {}\n",
    "\n",
    "\n",
    "    def _read_file(self, path: str) -> str:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "\n",
    "    @abstractmethod\n",
    "    def extract(self) -> Dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "    def _variants_from_filename(self, filename: str) -> Optional[Tuple[int, int]]:\n",
    "        m = re.search(r'(\\d+)_(\\d+)', filename)\n",
    "        if not m:\n",
    "            return None\n",
    "        return int(m.group(1)), int(m.group(2))\n",
    "\n",
    "    def _count_operations_core_functions(self, debug: bool = False) -> Dict[str, int]:\n",
    "        \"\"\"Count operations only in core cryptographic functions\"\"\"\n",
    "        return CoreFunctionOperationCounter.count_operations_in_core_functions(\n",
    "            self.content, self._get_cipher_family(), debug\n",
    "        )\n",
    "    \n",
    "    def _get_cipher_family(self) -> str:\n",
    "        \"\"\"Determine cipher family from profile\"\"\"\n",
    "        profile_info = CIPHER_PROFILES.get(self.profile, {})\n",
    "        return profile_info.get(\"family\", \"\")\n",
    "\n",
    "    # Keep the old method for reference (optional)\n",
    "    def _count_operations_from_ast(self) -> Dict[str, int]:\n",
    "        \"\"\"Original AST-based counting\"\"\"\n",
    "        op_counts = self._empty_counts()\n",
    "        \n",
    "        for func_name, body in self.definitions:\n",
    "            m = re.search(r'=\\s*(.*)', body, re.DOTALL)\n",
    "            rhs = m.group(1).strip() if m else body.strip()\n",
    "            try:\n",
    "                ast_tree = ExpressionParser.parse_expr_improved(rhs)\n",
    "                func_counts = count_operations_in_ast(ast_tree)\n",
    "                for key in op_counts:\n",
    "                    op_counts[key] += func_counts.get(key, 0)\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return op_counts\n",
    "    \n",
    "    def _empty_counts(self) -> Dict[str, int]:\n",
    "        return {\n",
    "            'xor_count': 0, 'rotl_count': 0, 'rotr_count': 0,\n",
    "            'add_count': 0, 'sub_count': 0, 'and_count': 0,\n",
    "            'sbox_count': 0, 'perm_count': 0, 'z_seq_usage': 0\n",
    "        }\n",
    "\n",
    "        ####\n",
    "        \n",
    "# =============================================================================\n",
    "# ENHANCED AST EXTRACTION WITH CRYPTOGRAPHIC SEMANTICS\n",
    "# =============================================================================\n",
    "def ast_to_nodes_edges_cryptographic(ast: Dict[str, Any], base_id: int = 0, \n",
    "                                   context: str = \"global\", cipher_family: str = \"\") -> Tuple[List[Dict], List[Dict], int]:\n",
    "    \"\"\"FIXED: Enhanced AST extraction with working cryptographic semantics\"\"\"\n",
    "    \n",
    "    nodes: List[Dict] = []\n",
    "    edges: List[Dict] = []\n",
    "    cur_id = base_id\n",
    "\n",
    "    def determine_cryptographic_semantics(node: Dict[str, Any], parent_context: str, \n",
    "                                        cipher_family: str) -> Dict[str, Any]:\n",
    "        \"\"\"FIXED: Working cryptographic role assignment\"\"\"\n",
    "        \n",
    "        op = (node.get(\"op\") or \"\").lower()\n",
    "        node_label = node.get(\"label\", \"\")\n",
    "        \n",
    "        semantics = {\n",
    "            \"crypto_role\": \"operation\",\n",
    "            \"crypto_strength\": 1.0,\n",
    "            \"diffusion_power\": 0.0,\n",
    "            \"nonlinearity\": 0.0,\n",
    "            \"data_flow_role\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        # Operation-specific cryptographic properties\n",
    "        crypto_ops = {\n",
    "            \"xor\": {\"crypto_role\": \"linear_mixing\", \"crypto_strength\": 1.0, \"nonlinearity\": 0.0},\n",
    "            \"and\": {\"crypto_role\": \"nonlinear_mixing\", \"crypto_strength\": 3.0, \"nonlinearity\": 3.0},\n",
    "            \"rotl\": {\"crypto_role\": \"diffusion\", \"diffusion_power\": 2.0, \"crypto_strength\": 1.5},\n",
    "            \"rotr\": {\"crypto_role\": \"diffusion\", \"diffusion_power\": 2.0, \"crypto_strength\": 1.5},\n",
    "            \"add\": {\"crypto_role\": \"modular_operation\", \"crypto_strength\": 2.5, \"nonlinearity\": 2.0},\n",
    "            \"sub\": {\"crypto_role\": \"modular_operation\", \"crypto_strength\": 2.5, \"nonlinearity\": 2.0},\n",
    "        }\n",
    "        \n",
    "        if op in crypto_ops:\n",
    "            semantics.update(crypto_ops[op])\n",
    "        \n",
    "        # Family-specific enhancements\n",
    "        if cipher_family == \"Feistel\":\n",
    "            if \"f_function\" in str(node_label).lower():\n",
    "                semantics.update({\n",
    "                    \"crypto_role\": \"feistel_f_function\",\n",
    "                    \"crypto_strength\": 4.0,\n",
    "                    \"nonlinearity\": 3.0,\n",
    "                    \"data_flow_role\": \"nonlinear_layer\"\n",
    "                })\n",
    "                \n",
    "        elif cipher_family == \"ARX\":\n",
    "            if op == \"add\":\n",
    "                semantics.update({\n",
    "                    \"crypto_role\": \"modular_addition\", \n",
    "                    \"crypto_strength\": 3.0,\n",
    "                    \"nonlinearity\": 2.5\n",
    "                })\n",
    "                \n",
    "        elif cipher_family == \"SPN\":\n",
    "            if \"sbox\" in str(node_label).lower():\n",
    "                semantics.update({\n",
    "                    \"crypto_role\": \"sbox_substitution\",\n",
    "                    \"crypto_strength\": 5.0,\n",
    "                    \"nonlinearity\": 4.0,\n",
    "                    \"data_flow_role\": \"confusion\"\n",
    "                })\n",
    "            elif \"p_layer\" in str(node_label).lower():\n",
    "                semantics.update({\n",
    "                    \"crypto_role\": \"permutation_layer\", \n",
    "                    \"diffusion_power\": 4.0,\n",
    "                    \"data_flow_role\": \"diffusion\"\n",
    "                })\n",
    "            \n",
    "        return semantics\n",
    "\n",
    "\n",
    "    def walk_cryptographic(node: Dict[str, Any], parent_id: Optional[int] = None, \n",
    "                         node_context: str = \"operation\") -> int:\n",
    "        nonlocal cur_id, nodes, edges\n",
    "        \n",
    "        nid = cur_id\n",
    "        cur_id += 1\n",
    "\n",
    "        # Get cryptographic semantics for this node\n",
    "        crypto_semantics = determine_cryptographic_semantics(node, node_context, cipher_family)\n",
    "        \n",
    "        # Create enriched node\n",
    "        node_data = {\n",
    "            \"id\": nid,\n",
    "            \"type\": \"op\" if 'op' in node else \"var\" if 'var' in node else \"literal\",\n",
    "            \"label\": node.get(\"op\") or node.get(\"var\") or str(node.get(\"literal\", \"\")),\n",
    "            \"context\": node_context,\n",
    "            **crypto_semantics  # Add all cryptographic semantics\n",
    "        }\n",
    "        \n",
    "        # Add literal value if present\n",
    "        if 'literal' in node:\n",
    "            node_data[\"value\"] = node['literal']\n",
    "            node_data[\"value_type\"] = \"numeric\"\n",
    "        elif 'string' in node:\n",
    "            node_data[\"value\"] = node['string'] \n",
    "            node_data[\"value_type\"] = \"string\"\n",
    "        \n",
    "        nodes.append(node_data)\n",
    "\n",
    "        # Process children with basic edges first\n",
    "        if parent_id is not None:\n",
    "            edges.append({\"source\": parent_id, \"target\": nid, \"type\": \"child\"})\n",
    "\n",
    "        # Handle different node types\n",
    "        if 'op' in node:\n",
    "            if node[\"op\"] in (\"ROTL\", \"ROTR\"):\n",
    "                if \"amount\" in node:\n",
    "                    amount_id = walk_cryptographic(node[\"amount\"], nid, \"rotation_amount\")\n",
    "                    edges.append({\"source\": nid, \"target\": amount_id, \"type\": \"amount\"})\n",
    "                if \"arg\" in node:\n",
    "                    arg_id = walk_cryptographic(node[\"arg\"], nid, \"rotation_arg\")\n",
    "                    edges.append({\"source\": nid, \"target\": arg_id, \"type\": \"arg\"})\n",
    "                    \n",
    "            elif node[\"op\"] in (\"FST\", \"SND\"):\n",
    "                if \"arg\" in node:\n",
    "                    arg_id = walk_cryptographic(node[\"arg\"], nid, f\"{node['op'].lower()}_arg\")\n",
    "                    edges.append({\"source\": nid, \"target\": arg_id, \"type\": \"arg\"})\n",
    "            \n",
    "            elif node[\"op\"] == \"APPLY\":\n",
    "                # In walk_cryptographic, inside elif node[\"op\"] == \"APPLY\":\n",
    "                if \"func\" in node:\n",
    "                    # === OLD BUGGY CODE ===\n",
    "                    # func_id = walk_cryptographic({\"var\": node[\"func\"]}, nid, \"function_name\")\n",
    "                    # edges.append({\"source\": nid, \"target\": func_id, \"type\": \"func\"})\n",
    "                    \n",
    "                    # === NEW FIXED CODE ===\n",
    "                    func_id = cur_id\n",
    "                    cur_id += 1\n",
    "                    \n",
    "                    # 1. Create a node for the function name\n",
    "                    func_node_data = {\n",
    "                        \"id\": func_id,\n",
    "                        \"type\": \"func_name\",\n",
    "                        \"label\": node[\"func\"],\n",
    "                        \"context\": \"apply_func\"  # More specific context\n",
    "                    }\n",
    "                    \n",
    "                    # 2. *** Apply cryptographic semantics TO THE FUNCTION NAME ***\n",
    "                    func_semantics = determine_cryptographic_semantics(func_node_data, node_context, cipher_family)\n",
    "                    func_node_data.update(func_semantics)\n",
    "                    \n",
    "                    # 3. Add the enriched node\n",
    "                    nodes.append(func_node_data)\n",
    "                    edges.append({\"source\": nid, \"target\": func_id, \"type\": \"func\"})\n",
    "                    # ========================\n",
    "                \n",
    "                if \"args\" in node:\n",
    "                    for pos, arg in enumerate(node[\"args\"]):\n",
    "                        child_id = walk_cryptographic(arg, nid, \"apply_arg\")\n",
    "                        edges.append({\"source\": nid, \"target\": child_id, \"type\": \"arg\", \"position\": pos})\n",
    "            \n",
    "            elif node[\"op\"] == \"LET\":\n",
    "                if \"bindings\" in node:\n",
    "                    for var_name, expr in node[\"bindings\"].items():\n",
    "                        binding_id = walk_cryptographic(expr, nid, f\"binding_{var_name}\")\n",
    "                        edges.append({\"source\": nid, \"target\": binding_id, \"type\": \"binding\", \"var\": var_name})\n",
    "                if \"body\" in node:\n",
    "                    body_id = walk_cryptographic(node[\"body\"], nid, \"let_body\")\n",
    "                    edges.append({\"source\": nid, \"target\": body_id, \"type\": \"body\"})\n",
    "            \n",
    "            elif node[\"op\"] == \"IF\":\n",
    "                if \"condition\" in node:\n",
    "                    cond_id = walk_cryptographic(node[\"condition\"], nid, \"condition\")\n",
    "                    edges.append({\"source\": nid, \"target\": cond_id, \"type\": \"condition\"})\n",
    "                if \"then\" in node:\n",
    "                    then_id = walk_cryptographic(node[\"then\"], nid, \"then_branch\")\n",
    "                    edges.append({\"source\": nid, \"target\": then_id, \"type\": \"then\"})\n",
    "                if \"else\" in node:\n",
    "                    else_id = walk_cryptographic(node[\"else\"], nid, \"else_branch\")\n",
    "                    edges.append({\"source\": nid, \"target\": else_id, \"type\": \"else\"})\n",
    "            \n",
    "            # Handle binary operations\n",
    "            elif \"left\" in node and \"right\" in node:\n",
    "                left_id = walk_cryptographic(node[\"left\"], nid, \"left_operand\")\n",
    "                edges.append({\"source\": nid, \"target\": left_id, \"type\": \"left\"})\n",
    "                right_id = walk_cryptographic(node[\"right\"], nid, \"right_operand\")\n",
    "                edges.append({\"source\": nid, \"target\": right_id, \"type\": \"right\"})\n",
    "            \n",
    "            # Handle generic args list\n",
    "            elif \"args\" in node:\n",
    "                for pos, arg in enumerate(node[\"args\"]):\n",
    "                    if isinstance(arg, dict):\n",
    "                        child_id = walk_cryptographic(arg, nid, f\"{node['op']}_arg\")\n",
    "                        edges.append({\"source\": nid, \"target\": child_id, \"type\": \"arg\", \"position\": pos})\n",
    "                \n",
    "        # Handle variables - try to re-parse complex expressions\n",
    "        elif 'var' in node:\n",
    "            var_value = node[\"var\"]\n",
    "            # Try to re-parse complex expressions that weren't parsed\n",
    "            if any(op in var_value for op in [' ', '(', ')', '=', '+', '-', '*', '/']):\n",
    "                try:\n",
    "                    reparsed = ExpressionParser.parse_expr_improved(var_value)\n",
    "                    if 'var' not in reparsed or reparsed['var'] != var_value:\n",
    "                        return walk_cryptographic(reparsed, parent_id, node_context)\n",
    "                except:\n",
    "                    pass  # Keep as variable if parsing fails\n",
    "                \n",
    "        return nid\n",
    "\n",
    "    root_id = walk_cryptographic(ast, None, context)\n",
    "    return nodes, edges, cur_id\n",
    "\n",
    "# =============================================================================\n",
    "# DETECT CRYPTOGRAPHIC PATTERNS IN AST\n",
    "# =============================================================================\n",
    "\n",
    "def detect_cryptographic_patterns(nodes: List[Dict], edges: List[Dict], cipher_family: str) -> Dict[str, Any]:\n",
    "    \"\"\"Detect high-level cryptographic patterns in the AST\"\"\"\n",
    "    \n",
    "    patterns = {\n",
    "        \"feistel_network\": False,\n",
    "        \"arx_operation_chains\": [],\n",
    "        \"spn_layers\": False,\n",
    "        \"key_schedule_complexity\": 0,\n",
    "        \"round_function_structure\": {},\n",
    "        \"cryptographic_operation_distribution\": {}\n",
    "    }\n",
    "    \n",
    "    if not nodes:\n",
    "        return patterns\n",
    "\n",
    "    # Convert to node lookup for easier traversal\n",
    "    node_dict = {node[\"id\"]: node for node in nodes}\n",
    "    \n",
    "    # Count cryptographic roles\n",
    "    crypto_roles = {}\n",
    "    for node in nodes:\n",
    "        role = node.get(\"crypto_role\", \"unknown\")\n",
    "        crypto_roles[role] = crypto_roles.get(role, 0) + 1\n",
    "    \n",
    "    patterns[\"cryptographic_operation_distribution\"] = crypto_roles\n",
    "\n",
    "    if cipher_family == \"Feistel\":\n",
    "        patterns.update(detect_feistel_patterns(nodes, edges, node_dict))\n",
    "    elif cipher_family == \"ARX\":\n",
    "        patterns.update(detect_arx_patterns(nodes, edges, node_dict))\n",
    "    elif cipher_family == \"SPN\":\n",
    "        patterns.update(detect_spn_patterns(nodes, edges, node_dict))\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "def detect_feistel_patterns(nodes: List[Dict], edges: List[Dict], node_dict: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"FIXED: Detect Feistel network by looking at the APPLY node's PARENT\"\"\"\n",
    "    patterns = {}\n",
    "    \n",
    "    # 1. Find F-function applications (the func_name nodes)\n",
    "    f_functions = [n for n in nodes if n.get(\"crypto_role\") == \"feistel_f_function\"]\n",
    "    \n",
    "    round_structures = []\n",
    "    for f_func in f_functions:\n",
    "        # 2. Find the parent APPLY node that *calls* this F-function\n",
    "        apply_node_id = None\n",
    "        for edge in edges:\n",
    "            if edge[\"target\"] == f_func[\"id\"] and edge.get(\"type\") == \"func\":\n",
    "                apply_node_id = edge[\"source\"]\n",
    "                break\n",
    "        \n",
    "        if not apply_node_id:\n",
    "            continue\n",
    "\n",
    "        # 3. Find the PARENT node of the APPLY node (i.e., where the output goes)\n",
    "        parent_xor_node_id = None\n",
    "        for edge in edges:\n",
    "            if edge[\"target\"] == apply_node_id and edge.get(\"type\") in [\"arg\", \"child\"]:\n",
    "                parent_xor_node_id = edge[\"source\"]\n",
    "                break\n",
    "\n",
    "        if not parent_xor_node_id:\n",
    "            continue\n",
    "            \n",
    "        # 4. Check if this parent node is an XOR\n",
    "        target_node = node_dict.get(parent_xor_node_id)\n",
    "        if target_node and target_node.get(\"label\") == \"XOR\":\n",
    "            round_structures.append({\n",
    "                \"f_function_apply_node\": apply_node_id,\n",
    "                \"mixing_operation\": target_node[\"id\"],\n",
    "            })\n",
    "    \n",
    "    patterns[\"feistel_rounds_detected\"] = len(round_structures)\n",
    "    patterns[\"round_structures\"] = round_structures\n",
    "    patterns[\"feistel_network\"] = len(round_structures) > 0\n",
    "    \n",
    "    return patterns\n",
    "    \n",
    "    \n",
    "\n",
    "def detect_arx_patterns(nodes: List[Dict], edges: List[Dict], node_dict: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"FIXED: Detect ARX chains by resolving LET-bindings\"\"\"\n",
    "    patterns = {}\n",
    "    arx_chains = []\n",
    "\n",
    "    # 1. Create a map of where variables are defined\n",
    "    #    variable_map = {\"var_name\": node_id_of_definition}\n",
    "    variable_map = {}\n",
    "    let_nodes = [n for n in nodes if n.get(\"label\") == \"LET\"]\n",
    "    for let_node in let_nodes:\n",
    "        # Find all binding edges from this LET node\n",
    "        binding_edges = [e for e in edges if e[\"source\"] == let_node[\"id\"] and e.get(\"type\") == \"binding\"]\n",
    "        for edge in binding_edges:\n",
    "            var_name = edge.get(\"var\")\n",
    "            def_node_id = edge.get(\"target\")\n",
    "            if var_name:\n",
    "                # Map the simple variable name (e.g., \"rs_x\") to the node that defines it (e.g., node 1)\n",
    "                variable_map[var_name] = def_node_id\n",
    "\n",
    "    # 2. Now, find all ADD operations\n",
    "    add_ops = [n for n in nodes if n.get(\"label\") == \"ADD\"]\n",
    "    \n",
    "    for add_op in add_ops:\n",
    "        found_rot_input = False\n",
    "        found_xor_output = False\n",
    "\n",
    "        # 3. Check the INPUTS to the ADD node\n",
    "        input_edges = [e for e in edges if e[\"source\"] == add_op[\"id\"] and e.get(\"type\") in [\"left\", \"right\", \"arg\"]]\n",
    "        for in_edge in input_edges:\n",
    "            input_node = node_dict.get(in_edge[\"target\"])\n",
    "            if not input_node:\n",
    "                continue\n",
    "\n",
    "            # Check if the input is a variable defined in our map\n",
    "            if input_node[\"type\"] == \"var\" and input_node[\"label\"] in variable_map:\n",
    "                # It's a variable! Find its *real* source.\n",
    "                real_source_node_id = variable_map[input_node[\"label\"]]\n",
    "                real_source_node = node_dict.get(real_source_node_id)\n",
    "                \n",
    "                if real_source_node and real_source_node.get(\"label\") in [\"ROTL\", \"ROTR\"]:\n",
    "                    found_rot_input = True\n",
    "                    break\n",
    "            # Check if the input is just a direct rotation\n",
    "            elif input_node.get(\"label\") in [\"ROTL\", \"ROTR\"]:\n",
    "                found_rot_input = True\n",
    "                break\n",
    "        \n",
    "        if not found_rot_input:\n",
    "            continue\n",
    "\n",
    "        # 4. Check the OUTPUTS of the ADD node\n",
    "        # We need to find the variable this ADD is bound to\n",
    "        add_binding_var = None\n",
    "        for var_name, def_node_id in variable_map.items():\n",
    "            if def_node_id == add_op[\"id\"]:\n",
    "                add_binding_var = var_name\n",
    "                break\n",
    "        \n",
    "        if not add_binding_var:\n",
    "            continue # This ADD isn't bound to a var, logic fails\n",
    "\n",
    "        # Find all nodes that *use* this variable\n",
    "        for node in nodes:\n",
    "            # We are looking for an XOR that uses this variable\n",
    "            if node.get(\"label\") != \"XOR\":\n",
    "                continue\n",
    "\n",
    "            # Check the inputs of this XOR node\n",
    "            xor_input_edges = [e for e in edges if e[\"source\"] == node[\"id\"] and e.get(\"type\") in [\"left\", \"right\", \"arg\"]]\n",
    "            for xor_edge in xor_input_edges:\n",
    "                xor_input_node = node_dict.get(xor_edge[\"target\"])\n",
    "                if xor_input_node and xor_input_node[\"type\"] == \"var\" and xor_input_node[\"label\"] == add_binding_var:\n",
    "                    found_xor_output = True\n",
    "                    arx_chains.append({\n",
    "                        \"add_op\": add_op[\"id\"],\n",
    "                        \"rotation_op_source\": \"resolved_from_var\",\n",
    "                        \"xor_op\": node[\"id\"],\n",
    "                        \"chain_length\": 3\n",
    "                    })\n",
    "                    break\n",
    "            if found_xor_output:\n",
    "                break\n",
    "    \n",
    "    patterns[\"arx_operation_chains\"] = arx_chains\n",
    "    patterns[\"arx_chain_density\"] = len(arx_chains) / max(len(nodes), 1)\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "\n",
    "def detect_spn_patterns(nodes: List[Dict], edges: List[Dict], node_dict: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"FIXED: Detect SPN layer patterns by looking at the APPLY node's PARENT\"\"\"\n",
    "    patterns = {}\n",
    "    \n",
    "    # 1. Find S-box applications (the func_name nodes)\n",
    "    sbox_ops = [n for n in nodes if n.get(\"crypto_role\") == \"sbox_substitution\"]\n",
    "    \n",
    "    sbox_perm_chains = []\n",
    "    for sbox_op in sbox_ops:\n",
    "        # 2. Find the parent APPLY node that *calls* this S-box function\n",
    "        apply_node_id = None\n",
    "        for edge in edges:\n",
    "            if edge[\"target\"] == sbox_op[\"id\"] and edge.get(\"type\") == \"func\":\n",
    "                apply_node_id = edge[\"source\"]\n",
    "                break\n",
    "        \n",
    "        if not apply_node_id:\n",
    "            continue\n",
    "\n",
    "        # 3. Find the PARENT node of the S-Box APPLY node (this should be the P-Layer APPLY node)\n",
    "        parent_player_node_id = None\n",
    "        for edge in edges:\n",
    "             if edge[\"target\"] == apply_node_id and edge.get(\"type\") in [\"arg\", \"child\"]:\n",
    "                parent_player_node_id = edge[\"source\"]\n",
    "                break\n",
    "        \n",
    "        if not parent_player_node_id:\n",
    "            continue\n",
    "\n",
    "        # 4. Check if this parent node is a P-Layer\n",
    "        target_node = node_dict.get(parent_player_node_id)\n",
    "        \n",
    "        is_p_layer = False\n",
    "        if target_node and target_node.get(\"crypto_role\") == \"permutation_layer\":\n",
    "            # Parent is the P-layer function node itself (e.g. p_layer_bitwise)\n",
    "            is_p_layer = True\n",
    "        elif target_node and target_node.get(\"label\") == \"APPLY\":\n",
    "            # Parent is an APPLY node, check if IT calls a P-layer function\n",
    "            for edge in edges:\n",
    "                if edge[\"source\"] == target_node[\"id\"] and edge.get(\"type\") == \"func\":\n",
    "                    func_node = node_dict.get(edge[\"target\"])\n",
    "                    if func_node and func_node.get(\"crypto_role\") == \"permutation_layer\":\n",
    "                        is_p_layer = True\n",
    "                        break\n",
    "\n",
    "        if is_p_layer:\n",
    "            sbox_perm_chains.append({\n",
    "                \"sbox_apply_node\": apply_node_id,\n",
    "                \"perm_apply_node\": target_node[\"id\"],\n",
    "                \"chain_length\": 2\n",
    "            })\n",
    "    \n",
    "    patterns[\"sbox_perm_chains\"] = sbox_perm_chains\n",
    "    patterns[\"spn_layers\"] = len(sbox_perm_chains) > 0\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ENHANCED FEISTEL EXTRACTOR WITH CRYPTOGRAPHIC DEPTH\n",
    "# =============================================================================\n",
    "\n",
    "class FeistelExtractor(CipherExtractor):\n",
    "    def _count_simon_operations(self, debug: bool = False) -> Dict[str, int]:\n",
    "        \"\"\"FIXED: Simon-specific operation counting\"\"\"\n",
    "        # Use the corrected operation counter\n",
    "        core_counts = CoreFunctionOperationCounter.count_operations_in_core_functions(\n",
    "            self.content, self._get_cipher_family(), debug\n",
    "        )\n",
    "        \n",
    "        # Simon-specific adjustments\n",
    "        core_counts['add_count'] = 0    # Simon doesn't use addition\n",
    "        core_counts['sub_count'] = 0    # Simon doesn't use subtraction  \n",
    "        core_counts['sbox_count'] = 0   # Simon has no S-boxes\n",
    "        core_counts['perm_count'] = 0   # Simon has no permutations\n",
    "        \n",
    "        return core_counts\n",
    "        \n",
    "        # if debug:\n",
    "        #     print(f\"\\n=== SIMON-SPECIFIC OPERATION COUNTS ===\")\n",
    "        #     for op, count in core_counts.items():\n",
    "        #         print(f\"{op}: {count}\")\n",
    "        \n",
    "        return core_counts\n",
    "\n",
    "    def _detect_z_sequence_usage(self) -> int:\n",
    "        \"\"\"Detect if Z-sequences are used in cryptographic context\"\"\"\n",
    "        crypto_funcs = self._get_cryptographic_core_functions()\n",
    "        \n",
    "        for func_name, body in crypto_funcs.items():\n",
    "            # Check if Z-sequences are used in key schedule or rounds\n",
    "            if re.search(r'(get_z_bit_val|z0|z1|z2|z3|z4).*(key|round|schedule)', body, re.IGNORECASE):\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def _extract_rotation_amounts(self) -> List[int]:\n",
    "        \"\"\"Extract rotation amounts from Feistel operations\"\"\"\n",
    "        rotation_amounts = []\n",
    "        \n",
    "        # Look specifically in F_function for Simon's rotations (1, 8, 2)\n",
    "        crypto_funcs = self._get_cryptographic_core_functions()\n",
    "        for func_name, body in crypto_funcs.items():\n",
    "            # Simon F_function pattern: word_rotl 1 x, word_rotl 8 x, word_rotl 2 x\n",
    "            rot_matches = re.findall(r'word_rotl\\s+(\\d+)', body)\n",
    "            for amount in rot_matches:\n",
    "                try:\n",
    "                    rotation_amounts.append(int(amount))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        # Simon typically uses specific rotation amounts (1, 8, 2)\n",
    "        if not rotation_amounts:\n",
    "            # Default Simon rotation amounts based on common implementations\n",
    "            rotation_amounts = [1, 8, 2]\n",
    "        \n",
    "        return list(set(rotation_amounts))\n",
    "\n",
    "    def _get_cryptographic_core_functions(self) -> Dict[str, str]:\n",
    "        \"\"\"Extract true cryptographic functions for Feistel ciphers\"\"\"\n",
    "        crypto_functions = {}\n",
    "        \n",
    "        # EXCLUDE configuration/helper functions\n",
    "        excluded_functions = {\n",
    "            'get_num_rounds', 'get_z_array_index', 'get_z_bit_val',\n",
    "            'z0', 'z1', 'z2', 'z3', 'z4', 'rho_const', 'block_size',\n",
    "            'key_size', 'word_size', 'num_rounds'\n",
    "        }\n",
    "        \n",
    "        # INCLUDE Feistel cryptographic core functions\n",
    "        feistel_priority = [\n",
    "            'F_function', 'simon_round', 'encrypt', 'decrypt',\n",
    "            'gen_key_schedule_rec', 'generate_key_schedule',\n",
    "            'encrypt_iterate', 'decrypt_iterate', \n",
    "            'encrypt_block', 'decrypt_block', 'decrypt_round_inv'\n",
    "        ]\n",
    "        \n",
    "        # First, get all definitions\n",
    "        definitions_dict = dict(self.definitions)\n",
    "        \n",
    "        # Priority 1: Explicit Feistel cryptographic functions\n",
    "        for func_name in feistel_priority:\n",
    "            if func_name in definitions_dict and func_name not in excluded_functions:\n",
    "                crypto_functions[func_name] = definitions_dict[func_name]\n",
    "        \n",
    "        # Priority 2: Functions containing Feistel operations\n",
    "        for func_name, body in self.definitions:\n",
    "            if (func_name not in crypto_functions and \n",
    "                func_name not in excluded_functions and\n",
    "                self._contains_feistel_operations(body)):\n",
    "                crypto_functions[func_name] = body\n",
    "        \n",
    "        return crypto_functions\n",
    "\n",
    "    def _contains_feistel_operations(self, body: str) -> bool:\n",
    "        \"\"\"Check if function body contains Feistel operations\"\"\"\n",
    "        feistel_indicators = [\n",
    "            r'word_rotl\\s+\\d+',  # rotations with amounts\n",
    "            r'F_function',        # F-function calls\n",
    "            r'simon_round',       # round function\n",
    "            r'\\bxor\\s+',         # bitwise operations  \n",
    "            r'\\band\\s+',\n",
    "            r'key_schedule',     # key expansion\n",
    "            r'encrypt', 'decrypt'\n",
    "        ]\n",
    "        \n",
    "        for indicator in feistel_indicators:\n",
    "            if re.search(indicator, body, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _analyze_feistel_structure(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze Feistel network structure and properties\"\"\"\n",
    "        structure_info = {\n",
    "            \"f_function_complexity\": 0,\n",
    "            \"round_structure_detected\": False,\n",
    "            \"left_right_halves\": False,\n",
    "            \"key_schedule_type\": \"simple\"\n",
    "        }\n",
    "        \n",
    "        # Analyze F-function complexity\n",
    "        f_func_body = None\n",
    "        for func_name, body in self._get_cryptographic_core_functions().items():\n",
    "            if 'F_function' in func_name:\n",
    "                f_func_body = body\n",
    "                break\n",
    "        \n",
    "        if f_func_body:\n",
    "            # Count operations in F-function\n",
    "            op_counts = CoreFunctionOperationCounter._count_operations_in_text(f_func_body, cipher_family = \"Feistel\")\n",
    "            structure_info[\"f_function_complexity\"] = sum(op_counts.values())\n",
    "        \n",
    "        # Check for left/right half structure\n",
    "        if re.search(r'\\b(left|right|L|R)\\b', self.content, re.IGNORECASE):\n",
    "            structure_info[\"left_right_halves\"] = True\n",
    "        \n",
    "        # Analyze key schedule complexity\n",
    "        key_schedule_complexity = 0\n",
    "        for func_name, body in self._get_cryptographic_core_functions().items():\n",
    "            if 'key_schedule' in func_name.lower():\n",
    "                op_counts = CoreFunctionOperationCounter._count_operations_in_text(body, cipher_family = \"Feistel\")\n",
    "                key_schedule_complexity = sum(op_counts.values())\n",
    "                break\n",
    "        \n",
    "        if key_schedule_complexity > 10:\n",
    "            structure_info[\"key_schedule_type\"] = \"complex\"\n",
    "        elif key_schedule_complexity > 5:\n",
    "            structure_info[\"key_schedule_type\"] = \"moderate\"\n",
    "        else:\n",
    "            structure_info[\"key_schedule_type\"] = \"simple\"\n",
    "        \n",
    "        return structure_info\n",
    "\n",
    "    def extract(self) -> Dict[str, Any]:\n",
    "        fname = os.path.basename(self.thy_path)\n",
    "        var = self._variants_from_filename(fname)\n",
    "        if not var:\n",
    "            raise ValueError(\"Filename doesn't contain block/key variant info\")\n",
    "        block_size, key_size = var\n",
    "        \n",
    "        # Get rounds from profile\n",
    "        rounds = None\n",
    "        cp = CIPHER_PROFILES.get(self.profile, {})\n",
    "        if cp:\n",
    "            for vname, vinfo in cp.get(\"variants\", {}).items():\n",
    "                if vinfo.get(\"block_size\") == block_size and vinfo.get(\"key_size\") == key_size:\n",
    "                    rounds = vinfo.get(\"rounds\")\n",
    "                    break\n",
    "\n",
    "        # === ENHANCED: FILTER AND PARSE CRYPTOGRAPHIC FUNCTIONS ===\n",
    "        core_functions = self._get_cryptographic_core_functions()\n",
    "        \n",
    "        # Parse only cryptographic core functions into enhanced AST\n",
    "        for fname_def, body in core_functions.items():\n",
    "            self.functions.append(fname_def)\n",
    "            \n",
    "            # Clean the body for better parsing\n",
    "            # clean_body = self._clean_function_body(body)\n",
    "            # m = re.search(r'=\\s*(.*)', clean_body, re.DOTALL)\n",
    "            # rhs = m.group(1).strip() if m else clean_body.strip()\n",
    "            # 1. Clean the body of comments\n",
    "            clean_body = self._clean_function_body(body)\n",
    "        \n",
    "            # 2. Find the *actual* expression.\n",
    "            rhs = \"\"\n",
    "            # Try to find '... = ...'\n",
    "            equals_match = re.search(r'=\\s*(.*)', clean_body, re.DOTALL)\n",
    "            if equals_match:\n",
    "                rhs = equals_match.group(1).strip()\n",
    "            else:\n",
    "                # If no '=', it might be a 'where' clause. Find the first quote.\n",
    "                quote_match = re.search(r'\"(.*?)\"', clean_body, re.DOTALL)\n",
    "                if quote_match:\n",
    "                    rhs = quote_match.group(1).strip()\n",
    "                else:\n",
    "                    rhs = clean_body # Fallback\n",
    "    \n",
    "            # 3. Handle 'fun'/'definition' definitions that have the name in the body, e.g.,\n",
    "            #    \"present_round ... = p_layer_bitwise ...\"\n",
    "            if rhs.startswith(fname_def):\n",
    "                # Split on the *first* equals sign and take the part after it\n",
    "                if '=' in rhs:\n",
    "                    rhs = rhs.split('=', 1)[1].strip()\n",
    "                    \n",
    "            # 4. === THIS IS THE KEY FIX ===\n",
    "            #    Aggressively strip any *single* layer of surrounding quotes\n",
    "            if rhs.startswith('\"'):\n",
    "                rhs = rhs[1:]\n",
    "            if rhs.endswith('\"'):\n",
    "                rhs = rhs[:-1]\n",
    "            rhs = rhs.strip()\n",
    "            # ============================\n",
    "            \n",
    "            # 5. Final cleanup of internal whitespace\n",
    "            rhs = re.sub(r'\\s+', ' ', rhs) \n",
    "            \n",
    "            # Add this line to confirm the fix\n",
    "            print(f\"DEBUG: Parsing {fname_def} with CLEANED RHS: [{rhs}]\")\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                ast_tree = ExpressionParser.parse_expr_improved(rhs)\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Failed to parse {fname_def}: {e}\")\n",
    "                ast_tree = {\"error\": \"parse_failed\", \"raw\": rhs[:100]}\n",
    "            \n",
    "            # Use enhanced cryptographic AST extraction\n",
    "            nodes_local, edges_local, _ = ast_to_nodes_edges_cryptographic(\n",
    "                ast_tree, base_id=len(self.nodes), context=fname_def, \n",
    "                cipher_family=self._get_cipher_family()\n",
    "            )\n",
    "            \n",
    "            # Detect cryptographic patterns in this function\n",
    "            crypto_patterns = detect_cryptographic_patterns(nodes_local, edges_local, self._get_cipher_family())\n",
    "            \n",
    "            # Enhanced function node with pattern information\n",
    "            func_node_id = len(self.nodes) + len(nodes_local)\n",
    "            func_node = {\n",
    "                \"id\": func_node_id, \n",
    "                \"type\": \"function\", \n",
    "                \"label\": fname_def,\n",
    "                \"cryptographic_patterns\": crypto_patterns\n",
    "            }\n",
    "            \n",
    "            self.nodes.append(func_node)\n",
    "            self.nodes.extend(nodes_local)\n",
    "            self.edges.extend(edges_local)\n",
    "            \n",
    "            if nodes_local:\n",
    "                self.edges.append({\"source\": func_node_id, \"target\": nodes_local[0][\"id\"], \"type\": \"contains\"})\n",
    "\n",
    "        # Use Simon-specific operation counting\n",
    "        op_counts = self._count_simon_operations(debug=False)\n",
    "        \n",
    "        # Enhanced Feistel feature detection\n",
    "        rotation_amounts = self._extract_rotation_amounts()\n",
    "        z_sequence_usage = self._detect_z_sequence_usage()\n",
    "        feistel_structure = self._analyze_feistel_structure()\n",
    "        \n",
    "        # Enhanced Feistel detection with cryptographic context\n",
    "        has_round_function = any('simon_round' in func for func in self.functions)\n",
    "        has_f_function = any('F_function' in func for func in self.functions)\n",
    "        has_enc_round = has_round_function\n",
    "        has_dec_round = any('decrypt_round' in func for func in self.functions)\n",
    "        has_key_schedule = any('key_schedule' in func.lower() for func in self.functions)\n",
    "\n",
    "        # Calculate Feistel-specific metrics\n",
    "        f_function_complexity = feistel_structure[\"f_function_complexity\"] or (\n",
    "            op_counts['xor_count'] + op_counts['and_count'] + op_counts['rotl_count']\n",
    "        )\n",
    "        feistel_balance = self._calculate_feistel_balance(op_counts)\n",
    "        \n",
    "        pdv = {\n",
    "            \"source_file\": os.path.basename(self.thy_path),\n",
    "            \"cipher_family\": \"Feistel\",\n",
    "            \"cipher_name\": self.profile,\n",
    "            \"block_size\": block_size,\n",
    "            \"key_size\": key_size,\n",
    "            \"rounds\": rounds,\n",
    "            \n",
    "            \"feistel_structure\": {\n",
    "                \"has_round_function\": int(has_round_function),\n",
    "                \"has_f_function\": int(has_f_function),\n",
    "                \"has_enc_round\": int(has_enc_round),\n",
    "                \"has_dec_round\": int(has_dec_round),\n",
    "                \"has_key_schedule\": int(has_key_schedule),\n",
    "                \"rotation_diversity\": len(set(rotation_amounts)),\n",
    "                \"max_rotation_amount\": max(rotation_amounts, default=0),\n",
    "                \"rotation_amounts\": rotation_amounts,\n",
    "                \"f_function_complexity\": f_function_complexity,\n",
    "                \"uses_z_sequence\": z_sequence_usage,\n",
    "                \"left_right_halves\": feistel_structure[\"left_right_halves\"],\n",
    "                \"key_schedule_complexity\": feistel_structure[\"key_schedule_type\"],\n",
    "                \"feistel_balance\": feistel_balance,\n",
    "            },\n",
    "            \n",
    "            \"ops_summary\": op_counts\n",
    "        }\n",
    "\n",
    "        self.pdv = pdv\n",
    "        \n",
    "        # Security scoring\n",
    "        scorer = SecurityScorer(self.profile, block_size, key_size, rounds if rounds is not None else 0)\n",
    "        sec_score, sec_label = scorer.compute()\n",
    "        cipher_variant = f\"{self.profile}_{block_size}_{key_size}\"\n",
    "        all_label_computations[cipher_variant] = sec_label\n",
    "\n",
    "        # Create unified PDV with cryptographic depth\n",
    "        processor = UnifiedPDVProcessor()\n",
    "        ast_data = {\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges, \n",
    "            \"functions\": self.functions\n",
    "        }\n",
    "        unified_pdv = processor.create_unified_pdv(pdv, ast_data)\n",
    "       \n",
    "        print(f\"\\n=== FEISTEL EXTRACTION SUMMARY: {cipher_variant} ===\")\n",
    "        print(f\"Security: {sec_score} ({sec_label})\")\n",
    "        print(f\"Rotation amounts: {rotation_amounts}\")\n",
    "        print(f\"Z-sequence usage: {z_sequence_usage}\")\n",
    "        print(f\"F-function complexity: {f_function_complexity}\")\n",
    "        print(f\"Feistel balance: {feistel_balance:.3f}\")\n",
    "        print(f\"Key schedule type: {feistel_structure['key_schedule_type']}\")\n",
    "        print(f\"Cryptographic functions: {self.functions}\")\n",
    "        print(f\"Total AST nodes: {len(self.nodes)}\")\n",
    "        print(f\"Total AST edges: {len(self.edges)}\")\n",
    "\n",
    "        return {\n",
    "            \"cipher_variant\": cipher_variant,\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges,\n",
    "            \"functions\": self.functions,\n",
    "            \"pdv\": pdv,\n",
    "            \"unified_pdv\": unified_pdv,\n",
    "            \"security_score\": sec_score,\n",
    "            \"security_label\": sec_label\n",
    "        }\n",
    "\n",
    "    def _calculate_feistel_balance(self, op_counts: Dict[str, int]) -> float:\n",
    "        \"\"\"Calculate how balanced the Feistel operations are\"\"\"\n",
    "        # Simon uses XOR, AND, ROTL in specific proportions\n",
    "        xor_ops = op_counts.get('xor_count', 0)\n",
    "        and_ops = op_counts.get('and_count', 0)\n",
    "        rotl_ops = op_counts.get('rotl_count', 0)\n",
    "        \n",
    "        total_feistel_ops = xor_ops + and_ops + rotl_ops\n",
    "        if total_feistel_ops == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Simon typically has more XORs than ANDs, with rotations for diffusion\n",
    "        # Good balance means having all three operation types present\n",
    "        operation_variety = len([op for op in [xor_ops, and_ops, rotl_ops] if op > 0]) / 3.0\n",
    "        \n",
    "        # Balance between linear (XOR) and nonlinear (AND) operations\n",
    "        if xor_ops + and_ops > 0:\n",
    "            linear_nonlinear_balance = min(xor_ops, and_ops) / max(xor_ops, and_ops)\n",
    "        else:\n",
    "            linear_nonlinear_balance = 0.0\n",
    "        \n",
    "        # Overall balance score\n",
    "        balance_score = (operation_variety + linear_nonlinear_balance) / 2.0\n",
    "        \n",
    "        return max(0.0, balance_score)\n",
    "\n",
    "    def _clean_function_body(self, body: str) -> str:\n",
    "        \"\"\"Clean function body for better parsing\"\"\"\n",
    "        # Remove block comments\n",
    "        body = re.sub(r'\\(\\*.*?\\*\\)', '', body, flags=re.DOTALL)\n",
    "        # Remove line comments\n",
    "        body = re.sub(r'--.*$', '', body, flags=re.MULTILINE)\n",
    "        # Remove extra whitespace\n",
    "        body = re.sub(r'\\s+', ' ', body)\n",
    "        return body.strip()\n",
    "\n",
    "\n",
    "        \n",
    "# =============================================================================\n",
    "# ENHANCED ARX EXTRACTOR WITH CRYPTOGRAPHIC DEPTH\n",
    "# =============================================================================\n",
    "\n",
    "class ARXExtractor(CipherExtractor):\n",
    "    def _count_speck_operations(self, debug: bool = False) -> Dict[str, int]:\n",
    "        \"\"\"FIXED: Speck-specific operation counting\"\"\"\n",
    "        # Use the corrected operation counter\n",
    "        core_counts = CoreFunctionOperationCounter.count_operations_in_core_functions(\n",
    "            self.content, self._get_cipher_family(), debug\n",
    "        )\n",
    "        \n",
    "        # Speck-specific adjustments\n",
    "        core_counts['and_count'] = 0      # Speck doesn't use AND\n",
    "        core_counts['sbox_count'] = 0     # Speck has no S-boxes\n",
    "        core_counts['perm_count'] = 0     # Speck has no permutations\n",
    "        core_counts['z_seq_usage'] = 0    # Speck doesn't use Z-sequences\n",
    "        \n",
    "        return core_counts\n",
    "\n",
    "    def _analyze_arx_structure(self) -> Dict[str, Any]:\n",
    "        \"\"\"FIXED: Analyze ARX structure and properties - CONSISTENT with Feistel\"\"\"\n",
    "        structure_info = {\n",
    "            \"enc_round_complexity\": 0,\n",
    "            \"rotation_diversity\": 0,\n",
    "            \"arx_operation_balance\": 0.0,\n",
    "            \"has_bidirectional_rotations\": False,\n",
    "            \"key_schedule_type\": \"simple\"\n",
    "        }\n",
    "        \n",
    "        # Analyze encryption round complexity\n",
    "        enc_round_body = None\n",
    "        for func_name, body in self._get_cryptographic_core_functions().items():\n",
    "            if 'speck_enc_round' in func_name:\n",
    "                enc_round_body = body\n",
    "                break\n",
    "        \n",
    "        if enc_round_body:\n",
    "            # Count operations in encryption round\n",
    "            op_counts = CoreFunctionOperationCounter._count_operations_in_text(enc_round_body, \"ARX\")\n",
    "            structure_info[\"enc_round_complexity\"] = sum(op_counts.values())\n",
    "        \n",
    "        # Check for bidirectional rotations\n",
    "        rotation_amounts = self._extract_rotation_amounts()\n",
    "        structure_info[\"rotation_diversity\"] = len(set(rotation_amounts))\n",
    "        \n",
    "        # Check if both left and right rotations are used\n",
    "        crypto_funcs = self._get_cryptographic_core_functions()\n",
    "        has_rotl = any('word_rotl' in body for _, body in crypto_funcs.items())\n",
    "        has_rotr = any('word_rotr' in body for _, body in crypto_funcs.items())\n",
    "        structure_info[\"has_bidirectional_rotations\"] = has_rotl and has_rotr\n",
    "        \n",
    "        # Analyze key schedule complexity\n",
    "        key_schedule_complexity = 0\n",
    "        for func_name, body in self._get_cryptographic_core_functions().items():\n",
    "            if 'key_schedule' in func_name.lower():\n",
    "                op_counts = CoreFunctionOperationCounter._count_operations_in_text(body, \"ARX\")\n",
    "                key_schedule_complexity = sum(op_counts.values())\n",
    "                break\n",
    "        \n",
    "        if key_schedule_complexity > 15:\n",
    "            structure_info[\"key_schedule_type\"] = \"complex\"\n",
    "        elif key_schedule_complexity > 8:\n",
    "            structure_info[\"key_schedule_type\"] = \"moderate\"\n",
    "        else:\n",
    "            structure_info[\"key_schedule_type\"] = \"simple\"\n",
    "        \n",
    "        return structure_info\n",
    "\n",
    "    def _get_cryptographic_core_functions(self) -> Dict[str, str]:\n",
    "        \"\"\"FIXED: Extract true cryptographic functions for ARX ciphers - CONSISTENT\"\"\"\n",
    "        crypto_functions = {}\n",
    "        \n",
    "        # EXCLUDE configuration/helper functions\n",
    "        excluded_functions = {\n",
    "            'get_num_rounds', 'get_shift_params', 'block_size',\n",
    "            'key_size', 'word_size', 'num_rounds', 'alpha', 'beta'\n",
    "        }\n",
    "        \n",
    "        # INCLUDE ARX cryptographic core functions - UPDATED to match theory files\n",
    "        arx_priority = [\n",
    "            'speck_enc_round', 'speck_dec_round', 'encrypt', 'decrypt',\n",
    "            'gen_key_schedule_rec', 'generate_key_schedule',\n",
    "            'encrypt_iterate', 'decrypt_iterate', \n",
    "            'encrypt_block', 'decrypt_block', 'decrypt_round_inv'\n",
    "        ]\n",
    "        \n",
    "        # First, get all definitions\n",
    "        definitions_dict = dict(self.definitions)\n",
    "        \n",
    "        # Priority 1: Explicit ARX cryptographic functions\n",
    "        for func_name in arx_priority:\n",
    "            if func_name in definitions_dict and func_name not in excluded_functions:\n",
    "                crypto_functions[func_name] = definitions_dict[func_name]\n",
    "        \n",
    "        # Priority 2: Functions containing ARX operations\n",
    "        for func_name, body in self.definitions:\n",
    "            if (func_name not in crypto_functions and \n",
    "                func_name not in excluded_functions and\n",
    "                self._contains_arx_operations(body)):\n",
    "                crypto_functions[func_name] = body\n",
    "        \n",
    "        return crypto_functions\n",
    "\n",
    "    def extract(self) -> Dict[str, Any]:\n",
    "        fname = os.path.basename(self.thy_path)\n",
    "        var = self._variants_from_filename(fname)\n",
    "        if not var:\n",
    "            raise ValueError(\"Filename doesn't contain variant info\")\n",
    "        block_size, key_size = var\n",
    "        \n",
    "        # Get rounds from profile\n",
    "        rounds = None\n",
    "        cp = CIPHER_PROFILES.get(self.profile, {})\n",
    "        if cp:\n",
    "            for vname, vinfo in cp.get(\"variants\", {}).items():\n",
    "                if vinfo.get(\"block_size\") == block_size and vinfo.get(\"key_size\") == key_size:\n",
    "                    rounds = vinfo.get(\"rounds\")\n",
    "                    break\n",
    "\n",
    "        # === ENHANCED: FILTER AND PARSE CRYPTOGRAPHIC FUNCTIONS ===\n",
    "        core_functions = self._get_cryptographic_core_functions()\n",
    "        \n",
    "        # Parse only cryptographic core functions into enhanced AST\n",
    "        for fname_def, body in core_functions.items():\n",
    "            self.functions.append(fname_def)\n",
    "            \n",
    "            # Clean the body for better parsing\n",
    "            # clean_body = self._clean_function_body(body)\n",
    "            # m = re.search(r'=\\s*(.*)', clean_body, re.DOTALL)\n",
    "            # rhs = m.group(1).strip() if m else clean_body.strip()\n",
    "            # 1. Clean the body AFTER extracting the RHS\n",
    "            # 1. Clean the body of comments\n",
    "            clean_body = self._clean_function_body(body)\n",
    "        \n",
    "            # 2. Find the *actual* expression.\n",
    "            rhs = \"\"\n",
    "            # Try to find '... = ...'\n",
    "            equals_match = re.search(r'=\\s*(.*)', clean_body, re.DOTALL)\n",
    "            if equals_match:\n",
    "                rhs = equals_match.group(1).strip()\n",
    "            else:\n",
    "                # If no '=', it might be a 'where' clause. Find the first quote.\n",
    "                quote_match = re.search(r'\"(.*?)\"', clean_body, re.DOTALL)\n",
    "                if quote_match:\n",
    "                    rhs = quote_match.group(1).strip()\n",
    "                else:\n",
    "                    rhs = clean_body # Fallback\n",
    "    \n",
    "            # 3. Handle 'fun'/'definition' definitions that have the name in the body, e.g.,\n",
    "            #    \"present_round ... = p_layer_bitwise ...\"\n",
    "            if rhs.startswith(fname_def):\n",
    "                # Split on the *first* equals sign and take the part after it\n",
    "                if '=' in rhs:\n",
    "                    rhs = rhs.split('=', 1)[1].strip()\n",
    "                    \n",
    "            # 4. === THIS IS THE KEY FIX ===\n",
    "            #    Aggressively strip any *single* layer of surrounding quotes\n",
    "            if rhs.startswith('\"'):\n",
    "                rhs = rhs[1:]\n",
    "            if rhs.endswith('\"'):\n",
    "                rhs = rhs[:-1]\n",
    "            rhs = rhs.strip()\n",
    "            # ============================\n",
    "            \n",
    "            # 5. Final cleanup of internal whitespace\n",
    "            rhs = re.sub(r'\\s+', ' ', rhs) \n",
    "            \n",
    "            # Add this line to confirm the fix\n",
    "            print(f\"DEBUG: Parsing {fname_def} with CLEANED RHS: [{rhs}]\")\n",
    "            \n",
    "            try:\n",
    "                ast_tree = ExpressionParser.parse_expr_improved(rhs)\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Failed to parse {fname_def}: {e}\")\n",
    "                ast_tree = {\"error\": \"parse_failed\", \"raw\": rhs[:100]}\n",
    "            \n",
    "            # Use enhanced cryptographic AST extraction\n",
    "            nodes_local, edges_local, _ = ast_to_nodes_edges_cryptographic(\n",
    "                ast_tree, base_id=len(self.nodes), context=fname_def, \n",
    "                cipher_family=self._get_cipher_family()\n",
    "            )\n",
    "            \n",
    "            # Detect cryptographic patterns in this function\n",
    "            crypto_patterns = detect_cryptographic_patterns(nodes_local, edges_local, self._get_cipher_family())\n",
    "            \n",
    "            # Enhanced function node with pattern information\n",
    "            func_node_id = len(self.nodes) + len(nodes_local)\n",
    "            func_node = {\n",
    "                \"id\": func_node_id, \n",
    "                \"type\": \"function\", \n",
    "                \"label\": fname_def,\n",
    "                \"cryptographic_patterns\": crypto_patterns\n",
    "            }\n",
    "            \n",
    "            self.nodes.append(func_node)\n",
    "            self.nodes.extend(nodes_local)\n",
    "            self.edges.extend(edges_local)\n",
    "            \n",
    "            if nodes_local:\n",
    "                self.edges.append({\"source\": func_node_id, \"target\": nodes_local[0][\"id\"], \"type\": \"contains\"})\n",
    "\n",
    "        # Use Speck-specific operation counting\n",
    "        op_counts = self._count_speck_operations(debug=False)\n",
    "        \n",
    "        # Enhanced ARX feature detection\n",
    "        rotation_amounts = self._extract_rotation_amounts()\n",
    "        shift_params_usage = self._detect_shift_params_usage()\n",
    "        arx_structure = self._analyze_arx_structure()  # NEW: Consistent structure analysis\n",
    "        \n",
    "        # Enhanced ARX detection with cryptographic context\n",
    "        has_enc_round = any('speck_enc_round' in func for func in self.functions)\n",
    "        has_dec_round = any('speck_dec_round' in func for func in self.functions)\n",
    "        has_key_schedule = any('key_schedule' in func.lower() for func in self.functions)\n",
    "        has_round_function = has_enc_round or has_dec_round\n",
    "\n",
    "        # Calculate ARX-specific metrics\n",
    "        arx_operation_balance = self._calculate_arx_balance(op_counts)\n",
    "        round_complexity = arx_structure[\"enc_round_complexity\"] or (\n",
    "            op_counts['add_count'] + op_counts['xor_count'] + op_counts['rotl_count'] + op_counts['rotr_count']\n",
    "        )\n",
    "        \n",
    "        pdv = {\n",
    "            \"source_file\": os.path.basename(self.thy_path),\n",
    "            \"cipher_family\": \"ARX\",\n",
    "            \"cipher_name\": \"Speck\",\n",
    "            \"block_size\": block_size,\n",
    "            \"key_size\": key_size,\n",
    "            \"rounds\": rounds,\n",
    "            \n",
    "            \"arx_structure\": {\n",
    "                \"has_enc_round\": int(has_enc_round),\n",
    "                \"has_dec_round\": int(has_dec_round),\n",
    "                \"has_key_schedule\": int(has_key_schedule),\n",
    "                \"has_round_function\": int(has_round_function),\n",
    "                \"enc_round_complexity\": round_complexity,\n",
    "                \"rotation_diversity\": arx_structure[\"rotation_diversity\"],\n",
    "                \"max_rotation_amount\": max(rotation_amounts, default=0),\n",
    "                \"rotation_amounts\": rotation_amounts,\n",
    "                \"arx_operation_balance\": arx_operation_balance,\n",
    "                \"has_bidirectional_rotations\": int(arx_structure[\"has_bidirectional_rotations\"]),\n",
    "                \"key_schedule_complexity\": arx_structure[\"key_schedule_type\"],\n",
    "            },\n",
    "            \n",
    "            \"shift_parameters\": {\n",
    "                \"shift_params_defined\": bool(shift_params_usage),\n",
    "                \"uses_shift_params\": shift_params_usage\n",
    "            },\n",
    "            \n",
    "            \"ops_summary\": op_counts\n",
    "        }\n",
    "        \n",
    "        self.pdv = pdv\n",
    "        \n",
    "        # Security scoring\n",
    "        scorer = SecurityScorer(\"Speck\", block_size, key_size, rounds if rounds is not None else 0)\n",
    "        sec_score, sec_label = scorer.compute()\n",
    "        cipher_variant = f\"Speck_{block_size}_{key_size}\"\n",
    "        all_label_computations[cipher_variant] = sec_label\n",
    "        \n",
    "        # Create unified PDV with cryptographic depth\n",
    "        processor = UnifiedPDVProcessor()\n",
    "        ast_data = {\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges, \n",
    "            \"functions\": self.functions\n",
    "        }\n",
    "        unified_pdv = processor.create_unified_pdv(pdv, ast_data)\n",
    "       \n",
    "        print(f\"\\n=== ARX EXTRACTION SUMMARY: {cipher_variant} ===\")\n",
    "        print(f\"Security: {sec_score} ({sec_label})\")\n",
    "        print(f\"Rotation amounts: {rotation_amounts}\")\n",
    "        print(f\"Shift parameters usage: {shift_params_usage}\")\n",
    "        print(f\"ARX operation balance: {arx_operation_balance:.3f}\")\n",
    "        print(f\"Bidirectional rotations: {arx_structure['has_bidirectional_rotations']}\")\n",
    "        print(f\"Key schedule type: {arx_structure['key_schedule_type']}\")\n",
    "        print(f\"Cryptographic functions: {self.functions}\")\n",
    "        print(f\"Total AST nodes: {len(self.nodes)}\")\n",
    "        print(f\"Total AST edges: {len(self.edges)}\")\n",
    "\n",
    "        return {\n",
    "            \"cipher_variant\": cipher_variant,\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges,\n",
    "            \"functions\": self.functions,\n",
    "            \"pdv\": pdv,\n",
    "            \"unified_pdv\": unified_pdv,\n",
    "            \"security_score\": sec_score,\n",
    "            \"security_label\": sec_label\n",
    "        }\n",
    "       \n",
    "    def _calculate_arx_balance(self, op_counts: Dict[str, int]) -> float:\n",
    "        \"\"\"Calculate how balanced the ARX operations are\"\"\"\n",
    "        add_ops = op_counts.get('add_count', 0)\n",
    "        rot_ops = op_counts.get('rotl_count', 0) + op_counts.get('rotr_count', 0)\n",
    "        xor_ops = op_counts.get('xor_count', 0)\n",
    "        \n",
    "        total_arx_ops = add_ops + rot_ops + xor_ops\n",
    "        if total_arx_ops == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Ideal balance would have similar counts of each operation type\n",
    "        ideal_per_op = total_arx_ops / 3.0\n",
    "        balance_score = 1.0 - (\n",
    "            abs(add_ops - ideal_per_op) + \n",
    "            abs(rot_ops - ideal_per_op) + \n",
    "            abs(xor_ops - ideal_per_op)\n",
    "        ) / (2.0 * total_arx_ops)\n",
    "        \n",
    "        return max(0.0, balance_score)\n",
    "\n",
    "    def _clean_function_body(self, body: str) -> str:\n",
    "        \"\"\"Clean function body for better parsing\"\"\"\n",
    "        # Remove block comments\n",
    "        body = re.sub(r'\\(\\*.*?\\*\\)', '', body, flags=re.DOTALL)\n",
    "        # Remove line comments\n",
    "        body = re.sub(r'--.*$', '', body, flags=re.MULTILINE)\n",
    "        # Remove extra whitespace\n",
    "        body = re.sub(r'\\s+', ' ', body)\n",
    "        return body.strip()\n",
    "\n",
    "    def _contains_arx_operations(self, body: str) -> bool:\n",
    "        \"\"\"Check if function body contains ARX operations\"\"\"\n",
    "        arx_indicators = [\n",
    "            r'word_rotl\\s+\\d+',    # rotations with amounts\n",
    "            r'word_rotr\\s+\\d+',\n",
    "            r'\\badd\\s+',           # modular addition\n",
    "            r'\\bxor\\s+',           # bitwise XOR\n",
    "            r'speck_enc_round',    # round function calls\n",
    "            r'speck_dec_round',\n",
    "            r'key_schedule',       # key expansion\n",
    "        ]\n",
    "        \n",
    "        for indicator in arx_indicators:\n",
    "            if re.search(indicator, body, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _detect_shift_params_usage(self) -> int:\n",
    "        \"\"\"Detect if shift parameters are used (Speck characteristic)\"\"\"\n",
    "        shift_indicators = [\n",
    "            r'get_shift_params', r'alpha_shift', r'beta_shift',\n",
    "            r'alpha', r'beta'\n",
    "        ]\n",
    "        \n",
    "        for indicator in shift_indicators:\n",
    "            if re.search(indicator, self.content, re.IGNORECASE):\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def _extract_rotation_amounts(self) -> List[int]:\n",
    "        \"\"\"Extract rotation amounts from ARX operations\"\"\"\n",
    "        rotation_amounts = []\n",
    "        \n",
    "        # Look for rotation operations in core functions\n",
    "        crypto_funcs = self._get_cryptographic_core_functions()\n",
    "        for func_name, body in crypto_funcs.items():\n",
    "            # Find word_rotl and word_rotr with numeric amounts\n",
    "            rotl_matches = re.findall(r'word_rotl\\s+(\\d+)', body)\n",
    "            rotr_matches = re.findall(r'word_rotr\\s+(\\d+)', body)\n",
    "            \n",
    "            for amount in rotl_matches + rotr_matches:\n",
    "                try:\n",
    "                    rotation_amounts.append(int(amount))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        # Speck typically uses specific rotation amounts (7, 2 for 32-bit)\n",
    "        if not rotation_amounts:\n",
    "            # Default Speck rotation amounts based on common implementations\n",
    "            rotation_amounts = [7, 2] if \"32\" in os.path.basename(self.thy_path) else [8, 3]\n",
    "        \n",
    "        return list(set(rotation_amounts))\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EXTRACTOR FOR HIGHT (GFN with ARX ops)\n",
    "# =============================================================================\n",
    "\n",
    "class HIGHTExtractor(CipherExtractor):\n",
    "    \n",
    "    def _count_hight_operations(self, debug: bool = False) -> Dict[str, int]:\n",
    "        \"\"\"FIXED: HIGHT-specific operation counting\"\"\"\n",
    "        # Use the corrected operation counter, now that it knows about \"HIGHT_ARX\"\n",
    "        core_counts = CoreFunctionOperationCounter.count_operations_in_core_functions(\n",
    "            self.content, self._get_cipher_family(), debug\n",
    "        )\n",
    "        \n",
    "        # HIGHT-specific adjustments (it doesn't use these)\n",
    "        core_counts['and_count'] = 0\n",
    "        core_counts['sbox_count'] = 0\n",
    "        core_counts['perm_count'] = 0\n",
    "        core_counts['z_seq_usage'] = 0\n",
    "        \n",
    "        return core_counts\n",
    "\n",
    "    def _get_cryptographic_core_functions(self) -> Dict[str, str]:\n",
    "        \"\"\"Extract true cryptographic functions for HIGHT\"\"\"\n",
    "        # This uses the exact list we defined in the previous step's fix\n",
    "        # for _is_core_function\n",
    "        all_funcs, _ = LineByLineFunctionExtractor.extract_core_functions(\n",
    "            self.content, \"HIGHT_ARX\", debug=False\n",
    "        )\n",
    "        return all_funcs\n",
    "\n",
    "    def _analyze_hight_structure(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze HIGHT network structure and properties\"\"\"\n",
    "        structure_info = {\n",
    "            \"round_complexity\": 0,\n",
    "            \"has_f_function_0\": False,\n",
    "            \"has_f_function_1\": False,\n",
    "            \"key_schedule_type\": \"simple\"\n",
    "        }\n",
    "        \n",
    "        f0_body = None\n",
    "        f1_body = None\n",
    "        round_body = None\n",
    "        \n",
    "        core_funcs = self._get_cryptographic_core_functions()\n",
    "\n",
    "        for func_name, body in core_funcs.items():\n",
    "            if 'hight_encryption_round' in func_name:\n",
    "                round_body = body\n",
    "            elif 'F_function_0' in func_name:\n",
    "                f0_body = body\n",
    "                structure_info[\"has_f_function_0\"] = True\n",
    "            elif 'F_function_1' in func_name:\n",
    "                f1_body = body\n",
    "                structure_info[\"has_f_function_1\"] = True\n",
    "\n",
    "        if round_body:\n",
    "            op_counts = CoreFunctionOperationCounter._count_operations_in_text(round_body, \"HIGHT_ARX\")\n",
    "            structure_info[\"round_complexity\"] = sum(op_counts.values())\n",
    "        \n",
    "        # Analyze key schedule complexity\n",
    "        key_schedule_complexity = 0\n",
    "        for func_name, body in core_funcs.items():\n",
    "            if 'key_schedule' in func_name.lower() or 'subkey_generation' in func_name.lower():\n",
    "                op_counts = CoreFunctionOperationCounter._count_operations_in_text(body, \"HIGHT_ARX\")\n",
    "                key_schedule_complexity += sum(op_counts.values())\n",
    "        \n",
    "        if key_schedule_complexity > 15:\n",
    "            structure_info[\"key_schedule_type\"] = \"complex\"\n",
    "        elif key_schedule_complexity > 8:\n",
    "            structure_info[\"key_schedule_type\"] = \"moderate\"\n",
    "        \n",
    "        return structure_info\n",
    "\n",
    "    def _detect_delta_sequence_usage(self) -> int:\n",
    "        \"\"\"Detect if delta sequences are used (HIGHT characteristic)\"\"\"\n",
    "        if re.search(r'\\b(delta0|get_delta_bit_val|constant_generation)\\b', self.content, re.IGNORECASE):\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    def _extract_rotation_amounts(self) -> List[int]:\n",
    "        \"\"\"Extract rotation amounts from HIGHT operations\"\"\"\n",
    "        rotation_amounts = []\n",
    "        crypto_funcs = self._get_cryptographic_core_functions()\n",
    "        for func_name, body in crypto_funcs.items():\n",
    "            # Find rotate_bits_left or word_rotl\n",
    "            rot_matches = re.findall(r'(?:word_rotl|rotate_bits_left)\\s+(\\d+)', body)\n",
    "            for amount in rot_matches:\n",
    "                try:\n",
    "                    rotation_amounts.append(int(amount))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        # From HIGHT.thy, F_function_0 uses (1, 2, 7) and F_function_1 uses (3, 4, 6)\n",
    "        if not rotation_amounts:\n",
    "            rotation_amounts = [1, 2, 7, 3, 4, 6]\n",
    "            \n",
    "        return list(set(rotation_amounts))\n",
    "\n",
    "    def _calculate_arx_balance(self, op_counts: Dict[str, int]) -> float:\n",
    "        \"\"\"Calculate how balanced the ARX operations are\"\"\"\n",
    "        add_ops = op_counts.get('add_count', 0) + op_counts.get('sub_count', 0)\n",
    "        rot_ops = op_counts.get('rotl_count', 0) + op_counts.get('rotr_count', 0)\n",
    "        xor_ops = op_counts.get('xor_count', 0)\n",
    "        \n",
    "        total_arx_ops = add_ops + rot_ops + xor_ops\n",
    "        if total_arx_ops == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Ideal balance would have similar counts of each operation type\n",
    "        ideal_per_op = total_arx_ops / 3.0\n",
    "        balance_score = 1.0 - (\n",
    "            abs(add_ops - ideal_per_op) +  \n",
    "            abs(rot_ops - ideal_per_op) +  \n",
    "            abs(xor_ops - ideal_per_op)\n",
    "        ) / (2.0 * total_arx_ops)\n",
    "        \n",
    "        return max(0.0, balance_score)\n",
    "\n",
    "    def extract(self) -> Dict[str, Any]:\n",
    "        fname = os.path.basename(self.thy_path)\n",
    "        var = self._variants_from_filename(fname)\n",
    "        if not var:\n",
    "            raise ValueError(\"Filename doesn't contain variant info\")\n",
    "        block_size, key_size = var\n",
    "        \n",
    "        # Get rounds from profile\n",
    "        rounds = None\n",
    "        cp = CIPHER_PROFILES.get(self.profile, {})\n",
    "        if cp:\n",
    "            for vname, vinfo in cp.get(\"variants\", {}).items():\n",
    "                if vinfo.get(\"block_size\") == block_size and vinfo.get(\"key_size\") == key_size:\n",
    "                    rounds = vinfo.get(\"rounds\")\n",
    "                    break\n",
    "        \n",
    "        # === FILTER AND PARSE CRYPTOGRAPHIC FUNCTIONS ===\n",
    "        core_functions = self._get_cryptographic_core_functions()\n",
    "        \n",
    "        for fname_def, body in core_functions.items():\n",
    "            self.functions.append(fname_def)\n",
    "            \n",
    "            # 1. Clean the body of comments\n",
    "            clean_body = self._clean_function_body(body)\n",
    "    \n",
    "            # 2. Find the *actual* expression.\n",
    "            rhs = \"\"\n",
    "            # Try to find '... = ...'\n",
    "            equals_match = re.search(r'=\\s*(.*)', clean_body, re.DOTALL)\n",
    "            if equals_match:\n",
    "                rhs = equals_match.group(1).strip()\n",
    "            else:\n",
    "                # If no '=', it might be a 'where' clause. Find the first quote.\n",
    "                quote_match = re.search(r'\"(.*?)\"', clean_body, re.DOTALL)\n",
    "                if quote_match:\n",
    "                    rhs = quote_match.group(1).strip()\n",
    "                else:\n",
    "                    rhs = clean_body # Fallback\n",
    "    \n",
    "            # 3. Handle 'fun'/'definition' definitions that have the name in the body\n",
    "            if rhs.startswith(fname_def):\n",
    "                if '=' in rhs:\n",
    "                    rhs = rhs.split('=', 1)[1].strip()\n",
    "                    \n",
    "            # 4. Aggressively strip any *single* layer of surrounding quotes\n",
    "            if rhs.startswith('\"'):\n",
    "                rhs = rhs[1:]\n",
    "            if rhs.endswith('\"'):\n",
    "                rhs = rhs[:-1]\n",
    "            rhs = rhs.strip()\n",
    "            \n",
    "            # 5. Final cleanup of internal whitespace\n",
    "            rhs = re.sub(r'\\s+', ' ', rhs) \n",
    "            \n",
    "            print(f\"DEBUG: Parsing {fname_def} with CLEANED RHS: [{rhs}]\")\n",
    "            \n",
    "            try:\n",
    "                ast_tree = ExpressionParser.parse_expr_improved(rhs)\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Failed to parse {fname_def}: {e}\")\n",
    "                ast_tree = {\"error\": \"parse_failed\", \"raw\": rhs[:100]}\n",
    "            \n",
    "            nodes_local, edges_local, _ = ast_to_nodes_edges_cryptographic(\n",
    "                ast_tree, base_id=len(self.nodes), context=fname_def, \n",
    "                cipher_family=self._get_cipher_family()\n",
    "            )\n",
    "            \n",
    "            crypto_patterns = detect_cryptographic_patterns(nodes_local, edges_local, self._get_cipher_family())\n",
    "            \n",
    "            func_node_id = len(self.nodes) + len(nodes_local)\n",
    "            func_node = {\n",
    "                \"id\": func_node_id, \n",
    "                \"type\": \"function\", \n",
    "                \"label\": fname_def,\n",
    "                \"cryptographic_patterns\": crypto_patterns\n",
    "            }\n",
    "            \n",
    "            self.nodes.append(func_node)\n",
    "            self.nodes.extend(nodes_local)\n",
    "            self.edges.extend(edges_local)\n",
    "            \n",
    "            if nodes_local:\n",
    "                self.edges.append({\"source\": func_node_id, \"target\": nodes_local[0][\"id\"], \"type\": \"contains\"})\n",
    "\n",
    "        # Use HIGHT-specific operation counting\n",
    "        op_counts = self._count_hight_operations(debug=False)\n",
    "        \n",
    "        # Enhanced HIGHT feature detection\n",
    "        rotation_amounts = self._extract_rotation_amounts()\n",
    "        delta_sequence_usage = self._detect_delta_sequence_usage()\n",
    "        hight_structure = self._analyze_hight_structure()\n",
    "        \n",
    "        has_round_function = any('hight_encryption_round' in func for func in self.functions)\n",
    "        has_key_schedule = any('key_schedule' in func.lower() for func in self.functions)\n",
    "        arx_operation_balance = self._calculate_arx_balance(op_counts)\n",
    "\n",
    "        pdv = {\n",
    "            \"source_file\": os.path.basename(self.thy_path),\n",
    "            \"cipher_family\": \"HIGHT_ARX\",  # Use our new family name\n",
    "            \"cipher_name\": self.profile,   # This will be \"HIGHT\"\n",
    "            \"block_size\": block_size,\n",
    "            \"key_size\": key_size,\n",
    "            \"rounds\": rounds,\n",
    "            \n",
    "            \"hight_structure\": {\n",
    "                \"has_round_function\": int(has_round_function),\n",
    "                \"has_f_function_0\": int(hight_structure[\"has_f_function_0\"]),\n",
    "                \"has_f_function_1\": int(hight_structure[\"has_f_function_1\"]),\n",
    "                \"has_key_schedule\": int(has_key_schedule),\n",
    "                \"round_complexity\": hight_structure[\"round_complexity\"],\n",
    "                \"rotation_diversity\": len(set(rotation_amounts)),\n",
    "                \"max_rotation_amount\": max(rotation_amounts, default=0),\n",
    "                \"rotation_amounts\": rotation_amounts,\n",
    "                \"arx_operation_balance\": arx_operation_balance,\n",
    "                \"uses_delta_sequence\": delta_sequence_usage,\n",
    "                \"key_schedule_complexity\": hight_structure[\"key_schedule_type\"],\n",
    "            },\n",
    "            \n",
    "            \"ops_summary\": op_counts\n",
    "        }\n",
    "        \n",
    "        self.pdv = pdv\n",
    "        \n",
    "        # Security scoring\n",
    "        scorer = SecurityScorer(self.profile, block_size, key_size, rounds if rounds is not None else 0)\n",
    "        sec_score, sec_label = scorer.compute()\n",
    "        cipher_variant = f\"{self.profile}_{block_size}_{key_size}\"\n",
    "        all_label_computations[cipher_variant] = sec_label\n",
    "        \n",
    "        # Create unified PDV with cryptographic depth\n",
    "        processor = UnifiedPDVProcessor()\n",
    "        ast_data = {\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges, \n",
    "            \"functions\": self.functions\n",
    "        }\n",
    "        unified_pdv = processor.create_unified_pdv(pdv, ast_data)\n",
    "        \n",
    "        print(f\"\\n=== HIGHT EXTRACTION SUMMARY: {cipher_variant} ===\")\n",
    "        print(f\"Security: {sec_score} ({sec_label})\")\n",
    "        print(f\"Rotation amounts: {rotation_amounts}\")\n",
    "        print(f\"Delta-sequence usage: {delta_sequence_usage}\")\n",
    "        print(f\"ARX operation balance: {arx_operation_balance:.3f}\")\n",
    "        print(f\"Key schedule type: {hight_structure['key_schedule_type']}\")\n",
    "        print(f\"Cryptographic functions: {self.functions}\")\n",
    "        print(f\"Total AST nodes: {len(self.nodes)}\")\n",
    "        print(f\"Total AST edges: {len(self.edges)}\")\n",
    "\n",
    "        return {\n",
    "            \"cipher_variant\": cipher_variant,\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges,\n",
    "            \"functions\": self.functions,\n",
    "            \"pdv\": pdv,\n",
    "            \"unified_pdv\": unified_pdv,\n",
    "            \"security_score\": sec_score,\n",
    "            \"security_label\": sec_label\n",
    "        }\n",
    "    \n",
    "    def _clean_function_body(self, body: str) -> str:\n",
    "        \"\"\"Clean function body for better parsing\"\"\"\n",
    "        # Remove block comments\n",
    "        body = re.sub(r'\\(\\*.*?\\*\\)', '', body, flags=re.DOTALL)\n",
    "        # Remove line comments\n",
    "        body = re.sub(r'--.*$', '', body, flags=re.MULTILINE)\n",
    "        # Remove extra whitespace\n",
    "        body = re.sub(r'\\s+', ' ', body)\n",
    "        return body.strip()\n",
    "\n",
    "   \n",
    "\n",
    "# =============================================================================\n",
    "# ENHANCED SPN EXTRACTOR WITH CRYPTOGRAPHIC DEPTH\n",
    "# =============================================================================\n",
    "\n",
    "class SPNExtractor(CipherExtractor):\n",
    "    def _count_present_operations(self, debug: bool = False) -> Dict[str, int]:\n",
    "        \"\"\"FIXED: PRESENT-specific operation counting\"\"\"\n",
    "        # Use the corrected operation counter\n",
    "        core_counts = CoreFunctionOperationCounter.count_operations_in_core_functions(\n",
    "            self.content, self._get_cipher_family(), debug\n",
    "        )\n",
    "        \n",
    "        # PRESENT-specific adjustments\n",
    "        core_counts['rotl_count'] = 0      # PRESENT doesn't use rotations\n",
    "        core_counts['rotr_count'] = 0\n",
    "        core_counts['add_count'] = 0       # PRESENT doesn't use addition\n",
    "        core_counts['sub_count'] = 0       # PRESENT doesn't use subtraction\n",
    "        core_counts['and_count'] = 0       # PRESENT doesn't use AND\n",
    "        core_counts['z_seq_usage'] = 0     # PRESENT doesn't use Z-sequences\n",
    "        \n",
    "\n",
    "        return core_counts\n",
    "\n",
    "\n",
    "    def _analyze_spn_structure(self) -> Dict[str, Any]:\n",
    "        \"\"\"FIXED: Analyze SPN structure and properties - CONSISTENT with others\"\"\"\n",
    "        structure_info = {\n",
    "            \"round_complexity\": 0,\n",
    "            \"has_sbox_layer\": False,\n",
    "            \"has_perm_layer\": False,\n",
    "            \"layer_separation\": False,\n",
    "            \"key_schedule_type\": \"simple\",\n",
    "            \"confusion_diffusion_balance\": 0.0\n",
    "        }\n",
    "        \n",
    "        # Analyze round complexity\n",
    "        round_body = None\n",
    "        for func_name, body in self._get_cryptographic_core_functions().items():\n",
    "            if 'present_round' in func_name:\n",
    "                round_body = body\n",
    "                break\n",
    "        \n",
    "        if round_body:\n",
    "            # Count operations in round function\n",
    "            op_counts = CoreFunctionOperationCounter._count_operations_in_text(round_body, \"SPN\")\n",
    "            structure_info[\"round_complexity\"] = sum(op_counts.values())\n",
    "        \n",
    "        # Check for layer separation\n",
    "        crypto_funcs = self._get_cryptographic_core_functions()\n",
    "        has_sbox = any('sbox' in func_name.lower() for func_name in crypto_funcs.keys())\n",
    "        has_perm = any('p_layer' in func_name.lower() for func_name in crypto_funcs.keys())\n",
    "        structure_info[\"has_sbox_layer\"] = has_sbox\n",
    "        structure_info[\"has_perm_layer\"] = has_perm\n",
    "        structure_info[\"layer_separation\"] = has_sbox and has_perm\n",
    "        \n",
    "        # Analyze key schedule complexity\n",
    "        key_schedule_complexity = 0\n",
    "        for func_name, body in self._get_cryptographic_core_functions().items():\n",
    "            if 'key_schedule' in func_name.lower() or 'key_update' in func_name.lower():\n",
    "                op_counts = CoreFunctionOperationCounter._count_operations_in_text(body, \"SPN\")\n",
    "                key_schedule_complexity = sum(op_counts.values())\n",
    "                break\n",
    "        \n",
    "        if key_schedule_complexity > 20:\n",
    "            structure_info[\"key_schedule_type\"] = \"complex\"\n",
    "        elif key_schedule_complexity > 10:\n",
    "            structure_info[\"key_schedule_type\"] = \"moderate\"\n",
    "        else:\n",
    "            structure_info[\"key_schedule_type\"] = \"simple\"\n",
    "        \n",
    "        return structure_info\n",
    "\n",
    "    def _get_cryptographic_core_functions(self) -> Dict[str, str]:\n",
    "        \"\"\"FIXED: Extract true cryptographic functions for SPN ciphers - CONSISTENT\"\"\"\n",
    "        crypto_functions = {}\n",
    "        \n",
    "        # EXCLUDE configuration/helper functions\n",
    "        excluded_functions = {\n",
    "            'get_num_rounds', 'block_size', 'key_size',\n",
    "            'word_size', 'num_rounds', 'sbox_table', 'sbox_inv_table',\n",
    "            'p_layer_map', 'p_layer_inv_map'\n",
    "        }\n",
    "        \n",
    "        # INCLUDE SPN cryptographic core functions - UPDATED to match theory files\n",
    "        spn_priority = [\n",
    "            'present_round', 'present_round_inv', 'sbox_layer', 'sbox_layer_inv',\n",
    "            'p_layer_bitwise', 'p_layer_inv_bitwise', 'present_encrypt', 'present_decrypt',\n",
    "            'present_encrypt_iterate', 'present_decrypt_iterate', 'encrypt', 'decrypt',\n",
    "            'key_schedule', 'key_update', 'build_key_list', 'extract_round_key',\n",
    "            'test_encrypt', 'test_decrypt'\n",
    "        ]\n",
    "        \n",
    "        # First, get all definitions\n",
    "        definitions_dict = dict(self.definitions)\n",
    "        \n",
    "        # Priority 1: Explicit SPN cryptographic functions\n",
    "        for func_name in spn_priority:\n",
    "            if func_name in definitions_dict and func_name not in excluded_functions:\n",
    "                crypto_functions[func_name] = definitions_dict[func_name]\n",
    "        \n",
    "        # Priority 2: Functions containing SPN operations\n",
    "        for func_name, body in self.definitions:\n",
    "            if (func_name not in crypto_functions and \n",
    "                func_name not in excluded_functions and\n",
    "                self._contains_spn_operations(body)):\n",
    "                crypto_functions[func_name] = body\n",
    "        \n",
    "        return crypto_functions\n",
    "\n",
    "    def extract(self) -> Dict[str, Any]:\n",
    "        fname = os.path.basename(self.thy_path)\n",
    "        var = self._variants_from_filename(fname)\n",
    "        if not var:\n",
    "            raise ValueError(\"Filename doesn't contain variant info\")\n",
    "        block_size, key_size = var\n",
    "        \n",
    "        # Get rounds from profile\n",
    "        rounds = None\n",
    "        cp = CIPHER_PROFILES.get(self.profile, {})\n",
    "        if cp:\n",
    "            for vname, vinfo in cp.get(\"variants\", {}).items():\n",
    "                if vinfo.get(\"block_size\") == block_size and vinfo.get(\"key_size\") == key_size:\n",
    "                    rounds = vinfo.get(\"rounds\")\n",
    "                    break\n",
    "\n",
    "        # === ENHANCED: FILTER AND PARSE CRYPTOGRAPHIC FUNCTIONS ===\n",
    "        core_functions = self._get_cryptographic_core_functions()\n",
    "        \n",
    "        # Parse only cryptographic core functions into enhanced AST\n",
    "        for fname_def, body in core_functions.items():\n",
    "            self.functions.append(fname_def)\n",
    "            \n",
    "            clean_body = self._clean_function_body(body)\n",
    "        \n",
    "            # 2. Find the *actual* expression.\n",
    "            rhs = \"\"\n",
    "            # Try to find '... = ...'\n",
    "            equals_match = re.search(r'=\\s*(.*)', clean_body, re.DOTALL)\n",
    "            if equals_match:\n",
    "                rhs = equals_match.group(1).strip()\n",
    "            else:\n",
    "                # If no '=', it might be a 'where' clause. Find the first quote.\n",
    "                quote_match = re.search(r'\"(.*?)\"', clean_body, re.DOTALL)\n",
    "                if quote_match:\n",
    "                    rhs = quote_match.group(1).strip()\n",
    "                else:\n",
    "                    rhs = clean_body # Fallback\n",
    "    \n",
    "            # 3. Handle 'fun'/'definition' definitions that have the name in the body, e.g.,\n",
    "            #    \"present_round ... = p_layer_bitwise ...\"\n",
    "            if rhs.startswith(fname_def):\n",
    "                # Split on the *first* equals sign and take the part after it\n",
    "                if '=' in rhs:\n",
    "                    rhs = rhs.split('=', 1)[1].strip()\n",
    "                    \n",
    "            # 4. === THIS IS THE KEY FIX ===\n",
    "            #    Aggressively strip any *single* layer of surrounding quotes\n",
    "            if rhs.startswith('\"'):\n",
    "                rhs = rhs[1:]\n",
    "            if rhs.endswith('\"'):\n",
    "                rhs = rhs[:-1]\n",
    "            rhs = rhs.strip()\n",
    "            # ============================\n",
    "            \n",
    "            # 5. Final cleanup of internal whitespace\n",
    "            rhs = re.sub(r'\\s+', ' ', rhs) \n",
    "            \n",
    "            # Add this line to confirm the fix\n",
    "            print(f\"DEBUG: Parsing {fname_def} with CLEANED RHS: [{rhs}]\")\n",
    "\n",
    "\n",
    "            try:\n",
    "                ast_tree = ExpressionParser.parse_expr_improved(rhs)\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Failed to parse {fname_def}: {e}\")\n",
    "                ast_tree = {\"error\": \"parse_failed\", \"raw\": rhs[:100]}\n",
    "            \n",
    "            # Use enhanced cryptographic AST extraction\n",
    "            nodes_local, edges_local, _ = ast_to_nodes_edges_cryptographic(\n",
    "                ast_tree, base_id=len(self.nodes), context=fname_def, \n",
    "                cipher_family=self._get_cipher_family()\n",
    "            )\n",
    "            \n",
    "            # Detect cryptographic patterns in this function\n",
    "            crypto_patterns = detect_cryptographic_patterns(nodes_local, edges_local, self._get_cipher_family())\n",
    "            \n",
    "            # Enhanced function node with pattern information\n",
    "            func_node_id = len(self.nodes) + len(nodes_local)\n",
    "            func_node = {\n",
    "                \"id\": func_node_id, \n",
    "                \"type\": \"function\", \n",
    "                \"label\": fname_def,\n",
    "                \"cryptographic_patterns\": crypto_patterns\n",
    "            }\n",
    "            \n",
    "            self.nodes.append(func_node)\n",
    "            self.nodes.extend(nodes_local)\n",
    "            self.edges.extend(edges_local)\n",
    "            \n",
    "            if nodes_local:\n",
    "                self.edges.append({\"source\": func_node_id, \"target\": nodes_local[0][\"id\"], \"type\": \"contains\"})\n",
    "\n",
    "        # Use PRESENT-specific operation counting\n",
    "        op_counts = self._count_present_operations(debug=False)\n",
    "        \n",
    "        # Enhanced SPN feature detection\n",
    "        sbox_info = self._analyze_sbox_structure()\n",
    "        perm_info = self._analyze_permutation_structure()\n",
    "        spn_structure = self._analyze_spn_structure()  # NEW: Consistent structure analysis\n",
    "        \n",
    "        # Enhanced SPN detection with cryptographic context\n",
    "        has_sbox_layer = any('sbox' in func.lower() for func in self.functions)\n",
    "        has_perm_layer = any('p_layer' in func.lower() for func in self.functions)\n",
    "        has_round_function = any('present_round' in func for func in self.functions)\n",
    "        has_key_schedule = any('key_schedule' in func.lower() for func in self.functions)\n",
    "\n",
    "        # Calculate SPN-specific metrics\n",
    "        round_complexity = spn_structure[\"round_complexity\"] or (\n",
    "            op_counts['sbox_count'] + op_counts['perm_count'] + op_counts['xor_count']\n",
    "        )\n",
    "        confusion_diffusion_balance = op_counts['sbox_count'] / max(op_counts['perm_count'] + op_counts['xor_count'], 1)\n",
    "        \n",
    "        pdv = {\n",
    "            \"source_file\": os.path.basename(self.thy_path),\n",
    "            \"cipher_family\": \"SPN\",\n",
    "            \"cipher_name\": \"PRESENT\",\n",
    "            \"block_size\": block_size,\n",
    "            \"key_size\": key_size,\n",
    "            \"rounds\": rounds,\n",
    "            \n",
    "            \"spn_structure\": {\n",
    "                \"has_sbox_layer\": int(has_sbox_layer),\n",
    "                \"has_perm_layer\": int(has_perm_layer),\n",
    "                \"has_round_function\": int(has_round_function),\n",
    "                \"has_key_schedule\": int(has_key_schedule),\n",
    "                \"round_complexity\": round_complexity,\n",
    "                \"sbox_size\": sbox_info[\"sbox_size\"],\n",
    "                \"sbox_nonlinearity\": sbox_info[\"sbox_nonlinearity\"],\n",
    "                \"sbox_applications\": op_counts['sbox_count'],\n",
    "                \"perm_applications\": op_counts['perm_count'],\n",
    "                \"xor_applications\": op_counts['xor_count'],\n",
    "                \"confusion_diffusion_balance\": confusion_diffusion_balance,\n",
    "                \"layer_separation\": int(spn_structure[\"layer_separation\"]),\n",
    "                \"key_schedule_complexity\": spn_structure[\"key_schedule_type\"],\n",
    "            },\n",
    "            \n",
    "            \"sbox_info\": sbox_info,\n",
    "            \"permutation_info\": perm_info,\n",
    "            \n",
    "            \"ops_summary\": op_counts\n",
    "        }\n",
    "        \n",
    "        self.pdv = pdv\n",
    "        \n",
    "        # Security scoring\n",
    "        scorer = SecurityScorer(\"PRESENT\", block_size, key_size, rounds if rounds is not None else 0)\n",
    "        sec_score, sec_label = scorer.compute()\n",
    "        cipher_variant = f\"PRESENT_{block_size}_{key_size}\"\n",
    "        all_label_computations[cipher_variant] = sec_label\n",
    "        \n",
    "        # Create unified PDV with cryptographic depth\n",
    "        processor = UnifiedPDVProcessor()\n",
    "        ast_data = {\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges, \n",
    "            \"functions\": self.functions\n",
    "        }\n",
    "        unified_pdv = processor.create_unified_pdv(pdv, ast_data)\n",
    "       \n",
    "        print(f\"\\n=== SPN EXTRACTION SUMMARY: {cipher_variant} ===\")\n",
    "        print(f\"Security: {sec_score} ({sec_label})\")\n",
    "        print(f\"S-box size: {sbox_info['sbox_size']} (defined: {sbox_info['sbox_defined']})\")\n",
    "        print(f\"Permutation: {perm_info['perm_type']} (size: {perm_info['perm_size']})\")\n",
    "        print(f\"Confusion-diffusion balance: {confusion_diffusion_balance:.3f}\")\n",
    "        print(f\"Layer separation: {spn_structure['layer_separation']}\")\n",
    "        print(f\"Key schedule type: {spn_structure['key_schedule_type']}\")\n",
    "        print(f\"Cryptographic functions: {self.functions}\")\n",
    "        print(f\"Total AST nodes: {len(self.nodes)}\")\n",
    "        print(f\"Total AST edges: {len(self.edges)}\")\n",
    "\n",
    "        return {\n",
    "            \"cipher_variant\": cipher_variant,\n",
    "            \"nodes\": self.nodes,\n",
    "            \"edges\": self.edges,\n",
    "            \"functions\": self.functions,\n",
    "            \"pdv\": pdv,\n",
    "            \"unified_pdv\": unified_pdv,\n",
    "            \"security_score\": sec_score,\n",
    "            \"security_label\": sec_label\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    #######\n",
    "\n",
    "\n",
    "    def _analyze_sbox_structure(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze S-box structure and properties\"\"\"\n",
    "        sbox_info = {\n",
    "            \"sbox_size\": 4,  # Default for PRESENT (4x4 S-box)\n",
    "            \"sbox_defined\": False,\n",
    "            \"sbox_nonlinearity\": 0.5,  # Typical for PRESENT\n",
    "            \"sbox_entries\": []\n",
    "        }\n",
    "        \n",
    "        # Look for S-box definition in the content\n",
    "        sbox_patterns = [\n",
    "            r'sbox_table\\s*=\\s*\\[([^\\]]+)\\]',\n",
    "            r'sbox\\s*=\\s*\\[([^\\]]+)\\]',\n",
    "            r'sbox_table.*?=\\s*\"([^\"]+)\"'\n",
    "        ]\n",
    "        \n",
    "        for pattern in sbox_patterns:\n",
    "            match = re.search(pattern, self.content, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                sbox_values = re.findall(r'0x[0-9A-Fa-f]+', match.group(1))\n",
    "                if sbox_values:\n",
    "                    sbox_info.update({\n",
    "                        \"sbox_defined\": True,\n",
    "                        \"sbox_size\": len(sbox_values),\n",
    "                        \"sbox_entries\": sbox_values[:16]  # First 16 entries\n",
    "                    })\n",
    "                    break\n",
    "        \n",
    "        return sbox_info\n",
    "\n",
    "    def _analyze_permutation_structure(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze permutation layer structure\"\"\"\n",
    "        perm_info = {\n",
    "            \"perm_defined\": False,\n",
    "            \"perm_type\": \"bit_permutation\",  # PRESENT uses bit permutation\n",
    "            \"perm_size\": 64  # Default for PRESENT-64\n",
    "        }\n",
    "        \n",
    "        # Look for permutation layer definitions\n",
    "        perm_indicators = [\n",
    "            r'p_layer',\n",
    "            r'permutation',\n",
    "            r'bit_permutation'\n",
    "        ]\n",
    "        \n",
    "        for indicator in perm_indicators:\n",
    "            if re.search(indicator, self.content, re.IGNORECASE):\n",
    "                perm_info[\"perm_defined\"] = True\n",
    "                break\n",
    "        \n",
    "        # Try to extract permutation size from context\n",
    "        if \"64\" in os.path.basename(self.thy_path):\n",
    "            perm_info[\"perm_size\"] = 64\n",
    "        elif \"128\" in os.path.basename(self.thy_path):\n",
    "            perm_info[\"perm_size\"] = 128\n",
    "            \n",
    "        return perm_info\n",
    "\n",
    "        \n",
    "\n",
    "    def _contains_spn_operations(self, body: str) -> bool:\n",
    "        \"\"\"Check if function body contains SPN operations\"\"\"\n",
    "        spn_indicators = [\n",
    "            r'sbox',                    # S-box operations\n",
    "            r'p_layer',                 # Permutation layer\n",
    "            r'permutation',             # Permutations\n",
    "            r'present_round',           # Round function\n",
    "            r'extract_round_key',       # Key handling\n",
    "            r'key_schedule',            # Key expansion\n",
    "        ]\n",
    "        \n",
    "        for indicator in spn_indicators:\n",
    "            if re.search(indicator, body, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _clean_function_body(self, body: str) -> str:\n",
    "        \"\"\"Clean function body for better parsing\"\"\"\n",
    "        # Remove block comments\n",
    "        body = re.sub(r'\\(\\*.*?\\*\\)', '', body, flags=re.DOTALL)\n",
    "        # Remove line comments\n",
    "        body = re.sub(r'--.*$', '', body, flags=re.MULTILINE)\n",
    "        # Remove extra whitespace\n",
    "        body = re.sub(r'\\s+', ' ', body)\n",
    "        return body.strip()\n",
    "\n",
    "\n",
    "def extract_isabelle_definitions(content: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Extract named definition/fun/function blocks with better pattern matching.\n",
    "    \"\"\"\n",
    "    blocks: List[Tuple[str, str]] = []\n",
    "    \n",
    "    # More robust pattern for definitions\n",
    "    patterns = [\n",
    "        # definition name where \"body\"\n",
    "        r'definition\\s+([A-Za-z0-9_]+)\\s*.*?\\s*where\\s*\"([^\"]*)\"',\n",
    "        # definition name = body\n",
    "        r'definition\\s+([A-Za-z0-9_]+)\\s*=\\s*([^;\\n]+)',\n",
    "        # fun/function with equations\n",
    "        r'(fun|function)\\s+([A-Za-z0-9_]+)\\s*.*?\\s*where\\s*\"([^\"]*)\"',\n",
    "        # Simple pattern for any identifier followed by equals\n",
    "        r'^([A-Za-z0-9_]+)\\s*=\\s*([^;\\n]+)$'\n",
    "    ]\n",
    "    \n",
    "    # Also look for pattern: name args = body\n",
    "    lines = content.split('\\n')\n",
    "    current_def = None\n",
    "    current_body = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Check for definition start\n",
    "        def_match = re.match(r'^(definition|fun|function)\\s+([A-Za-z0-9_]+)', line)\n",
    "        if def_match:\n",
    "            if current_def and current_body:\n",
    "                blocks.append((current_def, ' '.join(current_body)))\n",
    "            current_def = def_match.group(2)\n",
    "            current_body = []\n",
    "            # Extract initial body if present\n",
    "            if '=' in line or 'where' in line:\n",
    "                body_part = line.split('=', 1)[-1] if '=' in line else line.split('where', 1)[-1]\n",
    "                current_body.append(body_part.strip('\" '))\n",
    "        elif current_def and (line.startswith('|') or line.startswith('\"') or '=' in line):\n",
    "            # Continuation of definition\n",
    "            current_body.append(line.strip('\" '))\n",
    "        elif current_def and (line.startswith('lemma') or line.startswith('theorem') or line.startswith('end')):\n",
    "            # End of definition block\n",
    "            if current_body:\n",
    "                blocks.append((current_def, ' '.join(current_body)))\n",
    "            current_def = None\n",
    "            current_body = []\n",
    "    \n",
    "    # Don't forget the last definition\n",
    "    if current_def and current_body:\n",
    "        blocks.append((current_def, ' '.join(current_body)))\n",
    "    \n",
    "    # Also try the direct pattern matching\n",
    "    for pattern in patterns:\n",
    "        for match in re.finditer(pattern, content, re.DOTALL | re.MULTILINE):\n",
    "            groups = match.groups()\n",
    "            if len(groups) >= 2:\n",
    "                # The last group is usually the body, the one before is the name\n",
    "                if len(groups) == 2:\n",
    "                    name, body = groups\n",
    "                else:\n",
    "                    name, body = groups[1], groups[2] if len(groups) > 2 else groups[1]\n",
    "                \n",
    "                body = body.strip()\n",
    "                # Clean up the body\n",
    "                if body.endswith('\"'):\n",
    "                    body = body[:-1].strip()\n",
    "                if body.endswith(';'):\n",
    "                    body = body[:-1].strip()\n",
    "                \n",
    "                # Avoid duplicates\n",
    "                if not any(b[0] == name for b in blocks):\n",
    "                    blocks.append((name, body))\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# SecurityScorer (uses compute_security_score from cipher_profiles)\n",
    "# ----------------------------\n",
    "class SecurityScorer:\n",
    "    def __init__(self, cipher_name: str, block_size: int, key_size: int, rounds: int):\n",
    "        self.cipher_name = cipher_name\n",
    "        self.block_size = block_size\n",
    "        self.key_size = key_size\n",
    "        self.rounds = rounds\n",
    "        self.CIPHER_SEC_PARAMS = SecurityParams(self.cipher_name)\n",
    "\n",
    "    def compute(self) -> Tuple[float, str]:\n",
    "        # Get enhanced attack data\n",
    "        attack_info = ATTACK_DB.get(self.cipher_name, {}).get((self.block_size, self.key_size), {})\n",
    "\n",
    "        if attack_info:\n",
    "            # Use attack data if available\n",
    "            rounds = self.rounds\n",
    "            rounds_broken = attack_info.get('rounds_broken')\n",
    "            attack_type = attack_info.get('attack_type')\n",
    "            complexity = attack_info.get('complexity')\n",
    "            attacks = {attack_type: complexity} if attack_type and complexity else {}\n",
    "        else:\n",
    "            # Fall back to profile data\n",
    "            rounds = rounds\n",
    "            rounds_broken = None\n",
    "            attack_type = None\n",
    "            attacks = {}\n",
    "\n",
    "        score = compute_security_score(self.CIPHER_SEC_PARAMS, self.block_size, self.key_size, rounds, attacks, rounds_broken, attack_type)\n",
    "        label = security_label_from_score(score)\n",
    "        return score, label\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Extractor factory and runner\n",
    "# ----------------------------\n",
    "EXTRACTOR_MAP = {\n",
    "    \"Feistel\": FeistelExtractor,\n",
    "    \"ARX\": ARXExtractor,\n",
    "    \"SPN\": SPNExtractor,\n",
    "    \"HIGHT_ARX\": HIGHTExtractor\n",
    "}\n",
    "\n",
    "def build_ast_and_pdv_for_file(thy_path: str, profile_name: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Top-level: determine family and run extractor, with error handling.\"\"\"\n",
    "    try:\n",
    "        profile = CIPHER_PROFILES.get(profile_name)\n",
    "        if not profile:\n",
    "            raise ValueError(f\"Unknown profile: {profile_name}\")\n",
    "        family = profile.get(\"family\")\n",
    "        extractor_cls = EXTRACTOR_MAP.get(family)\n",
    "        \n",
    "        if extractor_cls is None:\n",
    "            raise ValueError(f\"No extractor for family '{family}'\")\n",
    "        print(profile_name)\n",
    "        extractor = extractor_cls(thy_path, profile_name)\n",
    "        return extractor.extract()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {thy_path}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "# Notebook-friendly runner\n",
    "def main(input_dir: str, output_dir: str, cipher_name: str):\n",
    "    \"\"\"\n",
    "    Run the extractor for all .thy files in input_dir that match the given cipher_name\n",
    "    and write .json outputs to output_dir.\n",
    "    \"\"\"\n",
    "    #from cipher_extractor import build_ast_and_pdv_for_file  # if in separate module adjust import\n",
    "    import os, json\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    thy_files = [f for f in os.listdir(input_dir) if f.endswith('.thy')]\n",
    "\n",
    "    summary = []\n",
    "    for f in thy_files:\n",
    "        if cipher_name.lower() not in f.lower():\n",
    "            continue\n",
    "        path = os.path.join(input_dir, f)\n",
    "        result = build_ast_and_pdv_for_file(path, cipher_name)\n",
    "        if not result:\n",
    "            continue\n",
    "        outname = f.replace('.thy', '.json')\n",
    "        outpath = os.path.join(output_dir, outname)\n",
    "        with open(outpath, 'w', encoding='utf-8') as fo:\n",
    "            json.dump(result, fo, indent=2)\n",
    "        summary.append({\"file\": f, \"cipher_variant\": result.get(\"cipher_variant\"), \"security_label\": result.get(\"security_label\")})\n",
    "        print(f\"Processed {f} -> {outpath}\")\n",
    "\n",
    "    # write summary\n",
    "    with open(os.path.join(output_dir, '_summary.json'), 'w', encoding='utf-8') as fo:\n",
    "        json.dump(summary, fo, indent=2)\n",
    "    print(\"Done. Summary saved.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_dir = \"generated_thy_variants\"\n",
    "output_dir = \"output_ast_V5/\"\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cipher_names = ['Simon', 'Speck', 'PRESENT']\n",
    "    for cipher_name in cipher_names:\n",
    "        print(f'\\n CIPHER: {cipher_name} \\n\\n')\n",
    "        main(input_dir, output_dir+cipher_name, cipher_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68480c83-e22f-4d24-88fe-98e71c4b972d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715c63f-685e-43b8-b243-b01d83bb98e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc85c366-a5de-4eb6-be33-21d4ba71ee41",
   "metadata": {},
   "source": [
    "#### Validating the security outputs with existing literature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b505f206-1648-492c-9d7f-a671fd629c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "  - Accuracy: 100.00% (23/23)\n",
      "  - Correct: 23\n",
      "  - Incorrect: 0\n"
     ]
    }
   ],
   "source": [
    "# existing literature ground truth cipher security labels\n",
    "\n",
    "GROUND_TRUTH = {\n",
    "    # Simon\n",
    "    \"Simon\": {\n",
    "        \"Simon_32_64\": \"low\", # https://en.wikipedia.org/wiki/Simon_%28cipher%29\n",
    "        \"Simon_48_72\": \"low\", \n",
    "        \"Simon_48_96\": \"medium\",\n",
    "        \"Simon_64_96\": \"medium\",\n",
    "        \"Simon_64_128\": \"high\",\n",
    "        \"Simon_96_96\": \"medium\",\n",
    "        \"Simon_96_144\": \"high\",\n",
    "        \"Simon_128_128\": \"high\",\n",
    "        \"Simon_128_192\": \"high\",\n",
    "        \"Simon_128_256\": \"high\"\n",
    "    },\n",
    "\n",
    "    # Speck\n",
    "    \"Speck\": {\n",
    "        \"Speck_32_64\": \"low\",\n",
    "        \"Speck_48_72\": \"low\",\n",
    "        \"Speck_48_96\": \"medium\", # https://en.wikipedia.org/wiki/Speck_%28cipher%29\n",
    "        \"Speck_64_96\": \"medium\",\n",
    "        \"Speck_64_128\": \"high\",\n",
    "        \"Speck_96_96\": \"medium\",\n",
    "        \"Speck_96_144\": \"high\",\n",
    "        \"Speck_128_128\": \"high\",\n",
    "        \"Speck_128_192\": \"high\",\n",
    "        \"Speck_128_256\": \"high\"\n",
    "    },\n",
    "    \n",
    "    # PRESENT\n",
    "    \"PRESENT\": {\n",
    "        \"PRESENT_64_40\": \"low\",\n",
    "        \"PRESENT_64_80\": \"medium\", # https://crypto.orange-labs.fr/papers/ches2007-450.pdf\n",
    "        \"PRESENT_64_128\": \"high\" #\n",
    "    }\n",
    "}\n",
    "\n",
    "def validate_security_labels(predictions: Dict[str, str],\n",
    "                             ground_truth: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compare predicted labels with ground truth and return summary stats.\n",
    "    predictions: dict mapping variant (e.g. \"Simon_64_128\") -> predicted label (\"low\"/\"medium\"/\"high\")\n",
    "    ground_truth: dict mapping variant -> true label (from literature / table above)\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    missing = []\n",
    "    mismatches = []\n",
    "\n",
    "    for var, true_label in ground_truth.items():\n",
    "        pred_label = predictions.get(var)\n",
    "        if pred_label is None:\n",
    "            missing.append(var)\n",
    "            continue\n",
    "        total += 1\n",
    "        if pred_label == true_label:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mismatches.append({\"variant\": var, \"predicted\": pred_label, \"expected\": true_label})\n",
    "\n",
    "    accuracy = correct / total if total > 0 else None\n",
    "\n",
    "    return {\n",
    "        \"total_checked\": total,\n",
    "        \"correct\": correct,\n",
    "        \"incorrect\": len(mismatches),\n",
    "        \"missing_predictions\": missing,\n",
    "        \"mismatches\": mismatches,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "    \n",
    "# Flatten the ground truth dictionary for the validator function\n",
    "flat_ground_truth = {k: v for family in GROUND_TRUTH.values() for k, v in family.items()}\n",
    "\n",
    "validation_results = validate_security_labels(all_label_computations, flat_ground_truth)\n",
    "\n",
    "# Print the validation summary\n",
    "accuracy_percent = validation_results['accuracy'] * 100\n",
    "print(f\"\\nValidation Summary:\")\n",
    "print(f\"  - Accuracy: {accuracy_percent:.2f}% ({validation_results['correct']}/{validation_results['total_checked']})\")\n",
    "print(f\"  - Correct: {validation_results['correct']}\")\n",
    "print(f\"  - Incorrect: {validation_results['incorrect']}\")\n",
    "\n",
    "if validation_results['mismatches']:\n",
    "    print(\"  - Mismatches:\")\n",
    "    for item in validation_results['mismatches']:\n",
    "        print(f\"    - {item['variant']}: Predicted '{item['predicted']}', Expected '{item['expected']}'\")\n",
    "        \n",
    "if validation_results['missing_predictions']:\n",
    "    print(f\"  - Missing Predictions: {validation_results['missing_predictions']}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c8c83-1e1a-4064-9620-8c6ec4c5b6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c9acf-5fa4-43d1-9fd8-c3c3f27ed0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c4b1b-9f6c-4311-8114-61e6ae4b1da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf574b63-2000-434d-8b42-6edfcc9b3ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cefe1c-d28e-47f3-a924-bf7c8f9e80b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b059e6-42cb-4725-8a0d-cbea67f94c02",
   "metadata": {},
   "source": [
    "#### TESTING CIPHERS -- HIGHT 64/128 -- MEDIUM SECURITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "befd2736-d954-424a-8d12-dd6f17d6ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGHT\n",
      "DEBUG: Parsing F_function_0 with CLEANED RHS: [xor (xor (rotate_bits_left x 1) (rotate_bits_left x 2)) (rotate_bits_left x 7)]\n",
      "DEBUG: Parsing F_function_1 with CLEANED RHS: [xor (xor (rotate_bits_left x 3) (rotate_bits_left x 4)) (rotate_bits_left x 6)]\n",
      "DEBUG: Parsing whitening_key_generation with CLEANED RHS: [[MK ! 12, MK ! 13, MK ! 14, MK ! 15, MK ! 0, MK ! 1, MK ! 2, MK ! 3]]\n",
      "DEBUG: Parsing generate_key_schedule_enc with CLEANED RHS: [(let delta = constant_generation; WK = whitening_key_generation initial_keys_list; SK = subkey_generation delta initial_keys_list in (WK, SK))]\n",
      "DEBUG: Parsing hight_encryption_round with CLEANED RHS: [[xor (X_i ! 7) ((F_function_0 (X_i ! 6) + SK ! (4 * i + 3)) mod 256), X_i ! 0, (X_i ! 1 + (xor (F_function_1 (X_i ! 0)) (SK ! (4 * i)))) mod 256, X_i ! 2, xor (X_i ! 3) ((F_function_0 (X_i ! 2) + SK ! (4 * i + 1)) mod 256), X_i ! 4, (X_i ! 5 + (xor (F_function_1 (X_i ! 4)) (SK ! (4 * i + 2)))) mod 256, X_i ! 6]]\n",
      "DEBUG: Parsing encrypt_iterate with CLEANED RHS: [(if i \\<ge> 32 then encryption_final_transformation X_i WK else encrypt_iterate (hight_encryption_round i X_i SK) WK SK (i + 1))]\n",
      "DEBUG: Parsing encrypt_block with CLEANED RHS: [(let (WK, SK) = generate_key_schedule_enc block_size key_size initial_keys_list; X_0 = encryption_initial_transformation P WK in encrypt_iterate X_0 WK SK 0)]\n",
      "\n",
      "=== HIGHT EXTRACTION SUMMARY: HIGHT_64_128 ===\n",
      "Security: 6.84 (medium)\n",
      "Rotation amounts: [1, 2, 3, 4, 6, 7]\n",
      "Delta-sequence usage: 1\n",
      "ARX operation balance: 0.939\n",
      "Key schedule type: simple\n",
      "Cryptographic functions: ['F_function_0', 'F_function_1', 'whitening_key_generation', 'generate_key_schedule_enc', 'hight_encryption_round', 'encrypt_iterate', 'encrypt_block']\n",
      "Total AST nodes: 213\n",
      "Total AST edges: 371\n",
      "Processed HIGHT_64_128.thy -> test_only_ciphers/HIGHT_64_128.json\n",
      "Done. Summary saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, json\n",
    "\n",
    "thy_files = [\"HIGHT_64_128.thy\"] \n",
    "cipher_name = 'HIGHT'\n",
    "summary = []\n",
    "output_dir = 'test_only_ciphers'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for f in thy_files:\n",
    "    if cipher_name.lower() not in f.lower():\n",
    "        continue\n",
    "    #path = os.path.join(input_dir, f)\n",
    "    result = build_ast_and_pdv_for_file(f, cipher_name)\n",
    "    if not result:\n",
    "        continue\n",
    "    outname = f.replace('.thy', '.json')\n",
    "    outpath = os.path.join(output_dir, outname)\n",
    "    with open(outpath, 'w', encoding='utf-8') as fo:\n",
    "        json.dump(result, fo, indent=2)\n",
    "    summary.append({\"file\": f, \"cipher_variant\": result.get(\"cipher_variant\"), \"security_label\": result.get(\"security_label\")})\n",
    "    print(f\"Processed {f} -> {outpath}\")\n",
    "\n",
    "# write summary\n",
    "with open(os.path.join(output_dir, '_summary.json'), 'w', encoding='utf-8') as fo:\n",
    "    json.dump(summary, fo, indent=2)\n",
    "print(\"Done. Summary saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba917c-22b7-4ff2-b2ad-d06a82620fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1f1fb-1543-4b68-ba5b-1618980272b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e30d1669-86ad-43bf-a949-57fafff97fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b7b0f-4604-414e-a69d-3ce79136977b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03f454-349a-4c6a-8910-26ab40503b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
